[{"content":"Recently, I faced a daunting task: migrating all of our existing product deals to a brand new, more comprehensive, and standardized set of canonical product categories. This was critical for improving product discoverability, ensuring consistent marketing, and enabling better reporting. Think of it as moving from a somewhat disorganized, ad-hoc filing system to a meticulously organized, hierarchical library catalog.\nThe problem? Our system had tens of thousands of deals, each with existing category assignments that were often inconsistent, incomplete, or simply didn\u0026rsquo;t map cleanly to the new structure. Manually re-categorizing everything was out of the question. It would have taken an absurd amount of time and been incredibly prone to errors. I needed an automated solution, but a simple keyword-based approach wouldn\u0026rsquo;t work. The nuances of product descriptions and the potential mismatches between the old and new categories demanded something far more intelligent.\nThe Challenge: Bridging the Old and New The core challenge was bridging the semantic gap between the existing (often messy) category assignments and the new canonical categories. Here are a few examples to illustrate the problem:\nOld: \u0026ldquo;mens-clothing.shirts-t-shirts\u0026rdquo; New: \u0026ldquo;Apparel.Men\u0026rsquo;s.Tops.T-Shirts\u0026rdquo; Old: \u0026ldquo;health-beauty.fragrance-cologne\u0026rdquo; New: \u0026ldquo;Beauty \u0026amp; Personal Care.Fragrances.Men\u0026rsquo;s Fragrances\u0026rdquo; Old: \u0026ldquo;home-decor\u0026rdquo; New: \u0026ldquo;Home \u0026amp; Garden.Home Decor.Candles \u0026amp; Home Fragrances\u0026rdquo; (for a scented candle deal) The old categories could be incomplete, use different wording, or have a different level of granularity. I couldn\u0026rsquo;t just create a simple lookup table. I needed a system that could:\nUnderstand the meaning of the product description, going beyond simple keyword matching. Leverage the existing category information, even if imperfect, as a valuable hint. Intelligently select the best match within the new canonical category hierarchy. My AI-Powered Solution: A Two-Stage Migration I developed a two-stage AI-powered system that combines the strengths of embedding-based similarity matching and the contextual reasoning of large language models (LLMs).\nStage 1: Embedding-Based Similarity ‚Äì Finding the Right Neighborhood The first stage leverages pre-computed embeddings of the new canonical categories. Embeddings are numerical representations that capture the semantic meaning of text. Similar concepts have similar embeddings. I calculated the embedding of each product deal\u0026rsquo;s description (including the title and any existing category information, after some complex preprocessing). Then, I compared this \u0026ldquo;deal embedding\u0026rdquo; to the embeddings of all the top-level categories in the new taxonomy.\n// (Simplified representation) import { calculateCosineSimilarity } from \u0026#39;./similarity\u0026#39;; import canonicalCategoryData from \u0026#39;./canonical_categories.json\u0026#39;; // My NEW category embeddings import { getAIClient } from \u0026#39;./ai_client\u0026#39;; // Interface to AI models async function migrateCategory(dealDetails) { const { title, description, existingCategories } = dealDetails; const { createTextEmbedding } = getAIClient(); // 1. Create an embedding for the deal, including (preprocessed) existing categories. const dealEmbedding = await createTextEmbedding( `${title} ${description} ${existingCategories ? prepareCategories(existingCategories) : \u0026#39;\u0026#39;}` ); // 2. Compare against top-level canonical category embeddings. const topLevelCategories = Object.entries(canonicalCategoryData) .map(([key, data]) =\u0026gt; [key, data.embedding]); let bestMatch = null; let highestScore = -Infinity; for (const [categoryName, categoryEmbedding] of topLevelCategories) { const similarity = calculateCosineSimilarity(dealEmbedding, categoryEmbedding); if (similarity \u0026gt; highestScore) { highestScore = similarity; bestMatch = categoryName; } } // ... (continued below) } I used cosine similarity to measure how \u0026ldquo;close\u0026rdquo; the embeddings are. A score of 1 is a perfect match; -1 is completely opposite. This quickly and efficiently identifies the general area within the new category structure where the deal likely belongs. If the similarity score exceeds a threshold (I used 0.8), I\u0026rsquo;m confident enough to assign the deal to that top-level category. Then, I repeat the process with the sub-categories of that top-level to get a more precise placement (e.g., \u0026ldquo;Apparel\u0026rdquo; -\u0026gt; \u0026ldquo;Men\u0026rsquo;s\u0026rdquo; -\u0026gt; \u0026ldquo;Tops\u0026rdquo; -\u0026gt; \u0026ldquo;T-Shirts\u0026rdquo;).\nStage 2: LLM Reasoning ‚Äì Refining the Choice What if the embedding similarity is below my threshold? This is where the LLM comes in, handling cases where:\nThe deal description is brief or uses unusual language. The existing categories are particularly unhelpful or misleading. The best fit in the new taxonomy isn\u0026rsquo;t immediately obvious. I construct a prompt for the LLM that includes:\nThe deal\u0026rsquo;s title and description. The (potentially cleaned-up) existing categories. A list of the new canonical categories to choose from. // (Continuing from the previous code snippet) const SIMILARITY_THRESHOLD = 0.8; async function migrateCategory(dealDetails) { // ... (previous code) // If similarity is high enough, we\u0026#39;re done! if (highestScore \u0026gt;= SIMILARITY_THRESHOLD) { const subCategories = canonicalCategoryData[bestMatch].children; // Get sub-categories const subCategoryMatch = await findBestSubCategory(dealEmbedding, subCategories); // Find the best sub-category return [bestMatch, subCategoryMatch].filter(Boolean).join(\u0026#39;.\u0026#39;); // Return \u0026#34;TopLevel.SubLevel\u0026#34; } // If similarity is low, bring in the LLM. const availableCategories = topLevelCategories.map(([categoryName]) =\u0026gt; categoryName); const suggestedCategory = await getCategorySuggestion(dealDetails, availableCategories); return suggestedCategory; } The getCategorySuggestion function (shown later) interacts with the LLM, providing the prompt and receiving the suggested category. The LLM acts like a \u0026ldquo;smart categorizer,\u0026rdquo; using its contextual understanding to make the best decision.\nThe Key: Cleaning Up the Existing Categories The most crucial and, I think, trickiest part of my solution is how I handle the existing category information. I can\u0026rsquo;t just ignore it; it often contains valuable clues. But I can\u0026rsquo;t trust it blindly, either. The refineExistingCategories function is the key to this delicate balance.\nexport function refineExistingCategories(categories: string, similarityScores: number[]): string { const keywords = categories .split(\u0026#39;,\u0026#39;) .map((cat) =\u0026gt; cat.split(\u0026#39;.\u0026#39;).map((subCat) =\u0026gt; subCat.split(\u0026#39;-\u0026#39;))) let i = 0; function filterKeywords(arr: any[]): any[] { return arr .map((item) =\u0026gt; { if (Array.isArray(item)) { return filterKeywords(item) } // THIS IS THE CORE LOGIC: Remove keywords with low similarity. return similarityScores[i++] \u0026gt; KEYWORD_SIMILARITY_THRESHOLD ? item : null }) .filter((item) =\u0026gt; item !== null) } return (filterKeywords(keywords) as string[][][]) .map((category) =\u0026gt; category .map((subCategory) =\u0026gt; { return subCategory.join(\u0026#39;-\u0026#39;) }) .join(\u0026#39;.\u0026#39;) ) .join(\u0026#39;,\u0026#39;) } Here\u0026rsquo;s a breakdown:\nDeconstruct: I break down the existing categories into a hierarchical structure of individual keywords. For example, \u0026ldquo;health-beauty.fragrance-cologne,mens-clothing\u0026rdquo; becomes [[[\u0026quot;health\u0026quot;, \u0026quot;beauty\u0026quot;], [\u0026quot;fragrance\u0026quot;, \u0026quot;cologne\u0026quot;]], [[\u0026quot;mens\u0026quot;, \u0026quot;clothing\u0026quot;]]].\nIndividual Keyword Embeddings: I create an embedding for each individual keyword from the old categories.\nSimilarity Check: I compare each keyword embedding to the embedding of the deal description ( without the old categories). This measures how relevant each individual keyword is to the core product information.\nStrategic Removal: If a keyword\u0026rsquo;s similarity is below a threshold (KEYWORD_SIMILARITY_THRESHOLD, which I set to 0.75), I remove it. This eliminates noise and prevents misleading information from influencing the LLM.\nReconstruct: I rebuild the \u0026ldquo;cleaned\u0026rdquo; existing categories string using only the remaining keywords.\nExample:\nLet\u0026rsquo;s say a deal for a men\u0026rsquo;s cologne has the old category \u0026ldquo;health-beauty.fragrance-cologne\u0026rdquo;.\nKeywords: [[[\u0026quot;health\u0026quot;, \u0026quot;beauty\u0026quot;], [\u0026quot;fragrance\u0026quot;, \u0026quot;cologne\u0026quot;]]] Embeddings: I create embeddings for \u0026ldquo;health\u0026rdquo;, \u0026ldquo;beauty\u0026rdquo;, \u0026ldquo;fragrance\u0026rdquo;, and \u0026ldquo;cologne\u0026rdquo;. Similarity: I compare each to the deal description embedding. \u0026ldquo;health\u0026rdquo; and \u0026ldquo;beauty\u0026rdquo; likely have low similarity; \u0026ldquo;fragrance\u0026rdquo; and \u0026ldquo;cologne\u0026rdquo; have high similarity. Removal: \u0026ldquo;health\u0026rdquo; and \u0026ldquo;beauty\u0026rdquo; are removed. Result: The cleaned category becomes \u0026ldquo;fragrance-cologne\u0026rdquo;. This \u0026ldquo;cleaned\u0026rdquo; category is then used in the LLM prompt, providing a much more focused and relevant hint. This significantly boosts the accuracy of the LLM\u0026rsquo;s suggestions.\nThe Full Code Here\u0026rsquo;s a more complete view of the code, including helper functions and the LLM interaction:\nimport { calculateCosineSimilarity } from \u0026#39;./similarity\u0026#39;; import canonicalCategoryData from \u0026#39;./canonical_categories.json\u0026#39;; import { getAIClient } from \u0026#39;./ai_client\u0026#39;; import { AppLogger } from \u0026#39;./logger\u0026#39;; type CategoryData = typeof canonicalCategoryData; const SIMILARITY_THRESHOLD = 0.8; const KEYWORD_SIMILARITY_THRESHOLD = 0.75; async function findBestMatch\u0026lt;T extends string\u0026gt;( { title, description, existingCategories, sourceEmbedding, comparisonEmbeddings }: { title: string; description: string; existingCategories?: string | null; sourceEmbedding: Array\u0026lt;number\u0026gt; | null; comparisonEmbeddings: Array\u0026lt;[T, Array\u0026lt;number\u0026gt;]\u0026gt; }, logger: AppLogger ): Promise\u0026lt;T | undefined\u0026gt; { let bestMatch: string | null = null; let highestScore = -Infinity; const { createTextEmbedding } = getAIClient(logger); if (sourceEmbedding !== null) { // Calculate cosine similarities and find the best match (embedding stage). comparisonEmbeddings.forEach(([targetCategory, targetEmbedding]) =\u0026gt; { const similarity = calculateCosineSimilarity(sourceEmbedding, targetEmbedding); if (similarity \u0026gt; highestScore) { highestScore = similarity; bestMatch = targetCategory; } }); } if (highestScore \u0026gt;= SIMILARITY_THRESHOLD) return bestMatch as T; // --- LLM Fallback (if embedding similarity is low) --- const targetCategoryNames = comparisonEmbeddings.map(([category]) =\u0026gt; category); // No existing categories? Simple LLM prompt. if (!existingCategories) { return await getCategorySuggestion\u0026lt;T\u0026gt;( `Product title: ${title}\\nProduct description: ${description}\\nAvailable categories:\\n`, targetCategoryNames, logger ); } // Existing categories? Refine them *first*! const categoryKeywords = existingCategories.split(/[^a-zA-Z0-9]/g); const keywordEmbeddings = await Promise.all(categoryKeywords.map((keyword) =\u0026gt; createTextEmbedding(keyword))); const productEmbeddingWithoutCategories = await createTextEmbedding(`${title} ${description}`); if (keywordEmbeddings.every((e) =\u0026gt; e !== null) \u0026amp;\u0026amp; productEmbeddingWithoutCategories) { const similarities = (keywordEmbeddings as unknown as number[][]).map((embedding) =\u0026gt; calculateCosineSimilarity(embedding, productEmbeddingWithoutCategories) ); const refinedCategories = refineExistingCategories(existingCategories, similarities); const prompt = `Product title: ${title}\\nProduct description: ${description}\\nPrevious categories: ${refinedCategories}\\nAvailable categories:\\n`; return await getCategorySuggestion\u0026lt;T\u0026gt;(prompt, targetCategoryNames, logger); } } async function getCategorySuggestion\u0026lt;T extends string\u0026gt;( partialPrompt: string, availableCategories: T[], logger: AppLogger ): Promise\u0026lt;T | undefined\u0026gt; { const { createChatCompletion } = getAIClient(logger); const suggestion = await createChatCompletion({ systemMessage: \u0026#39;You are a categorization assistant that helps choose new product categories during a taxonomy migration.\u0026#39;, userMessage: `${partialPrompt}${availableCategories.join(\u0026#39;, \u0026#39;)}\\nNew category:`, }); if (!suggestion) { return undefined; } // Ensure the suggestion is one of the available categories (case-insensitive). return availableCategories.find((c) =\u0026gt; c.toLowerCase() === suggestion.trim().toLowerCase()); } export function prepareCategories(categories: string) { return [...new Set(categories.split(/[^a-zA-Z0-9]/g))].join(\u0026#39; \u0026#39;) } export async function migrateCategory( dealDetails: { title: string; description: string; existingCategories?: string | null; }, logger: AppLogger ) { const { createTextEmbedding } = getAIClient(logger); const { title, description, existingCategories } = dealDetails; const dealEmbedding = await createTextEmbedding( `${title} ${description}${existingCategories ? ` ${prepareCategories(existingCategories)}` : \u0026#39;\u0026#39;}` ); const topLevelCategories = Object.entries(canonicalCategoryData).map\u0026lt; [keyof CategoryData, number[]] \u0026gt;(([key, data]) =\u0026gt; [key, data.embedding]); const topLevelMatch = await findBestMatch\u0026lt;keyof CategoryData\u0026gt;( { sourceEmbedding: dealEmbedding, comparisonEmbeddings: topLevelCategories, title, description, existingCategories, }, logger ); if (!topLevelMatch) { return null; } const subLevelMatch = await findBestMatch\u0026lt;string\u0026gt;( { title, description, existingCategories, sourceEmbedding: dealEmbedding, comparisonEmbeddings: canonicalCategoryData[topLevelMatch].children as [string, number[]][], }, logger ); return [topLevelMatch, subLevelMatch].filter(Boolean).join(\u0026#39;.\u0026#39;); } Key Results and Benefits This AI-powered migration system was a huge success. It allowed me to:\nDramatically improve accuracy: The combination of embeddings and LLMs significantly outperformed any manual or rule-based approach I could have devised. Save enormous amounts of time: What would have taken weeks or months of manual effort was completed in a fraction of the time. Ensure consistency: The automated system applied the new taxonomy consistently across all deals. Handle complexity: The system gracefully handled variations in product descriptions and ambiguities in the existing categories. Be adaptable: I can easily fine-tune the system (e.g., adjust the similarity thresholds) or update it as the canonical category structure evolves. This task is an example of how AI can be used to tackle complex, real-world data challenges. By combining different AI techniques and focusing on the nuances of the problem, I was able to build a solution that was both powerful and practical. The key was understanding the strengths of each approach ‚Äì embeddings for efficient similarity matching, LLMs for contextual understanding, and careful preprocessing to clean up noisy data ‚Äì and combining them in a resilient way.\n","permalink":"https://leihuang.me/posts/category-mapping-with-embedding/","summary":"\u003cp\u003eRecently, I faced a daunting task: migrating all of our existing product deals to a brand new, more comprehensive, and standardized set of canonical product categories. This was critical for improving product discoverability, ensuring consistent marketing, and enabling better reporting. Think of it as moving from a somewhat disorganized, ad-hoc filing system to a meticulously organized, hierarchical library catalog.\u003c/p\u003e\n\u003cp\u003eThe problem? Our system had \u003cem\u003etens of thousands\u003c/em\u003e of deals, each with existing category assignments that were often inconsistent, incomplete, or simply didn\u0026rsquo;t map cleanly to the new structure. Manually re-categorizing everything was out of the question. It would have taken an absurd amount of time and been incredibly prone to errors. I needed an automated solution, but a simple keyword-based approach wouldn\u0026rsquo;t work. The nuances of product descriptions and the potential mismatches between the old and new categories demanded something far more intelligent.\u003c/p\u003e","title":"Category Mapping with Embedding"},{"content":"I wrote about time-slicing with CPS technique in the last blog post. The solution I proposed has two drawbacks:\nThe control over task scheduling is too weak. Task slicing relies entirely on hacking the JavaScript engine\u0026rsquo;s event loop, and it\u0026rsquo;s impossible to arbitrarily pause and resume. This makes it impossible to precisely time the slices; you can only set them based on subjective experience (the example I provided uses 500 as the interval). However, 500 tasks might still be too long, causing the main thread to be blocked for too long. Or it might be too short, not fully utilizing the current call stack. setTimeout\u0026rsquo;s timing is inaccurate, and the actual time interval will have deviations. The result is that the delays of each task accumulate, significantly increasing the total task completion time. An alternative solution: Coroutine If a computational task can suspend itself and yield execution to other tasks, it\u0026rsquo;s a coroutine.\nIn JavaScript, we can arbitrarily pause and resume a program with Generators.\nFirst, we implement a coroutine scheduler, which isn\u0026rsquo;t very complex:\nfunction run(coroutine, threshold = 1, options = { timeout: 160 }) { return new Promise(function (resolve, reject) { const iterator = coroutine() window.requestIdleCallback(step, options) function step(deadline) { const minTime = Math.max(0.5, threshold) try { while (deadline.timeRemaining() \u0026gt; minTime) { const { value, done } = iterator.next() if (done) { resolve(value) return } } } catch (e) { reject(e) return } // If we reach here, it means the task timed out. Place the remaining task in the next idle period. window.requestIdleCallback(step, options) } }) } The run scheduler uses requestIdleCallback to get the browser\u0026rsquo;s remaining time budget. Within this time budget, the scheduler iteratively executes the passed-in coroutine (iterator.next()). If the task completes, the loop terminates, and the Promise resolves. If it times out, the remaining task is placed in the next idle period via requestIdleCallback.\nThe indexNews task we were dealing with was essentially a list fold operation. We can implement a coroutine version of reduce to help us accomplish the same task we did with for loop.\nfunction* reduce(array, fn, initial) { let result = initial || array[0] for (let i = 0; i \u0026lt; array.length; i++) { result = yield* fn(result, array[i], i, array) } return result } function sliceTask(fn, yieldInterval = 10) { let yieldCount = 0 return function* sliced(...params) { let result = fn(...params) if (yieldCount++ \u0026gt; yieldInterval) { yieldCount = 0 yield } return result } } function reduceAsync(array, reducer, initial) { return run(compute) function* compute() { return yield* reduce(array, sliceTask(reducer, 20), initial) } } const indexedData = await reduceAsync( newsList, (newsMap, item) =\u0026gt; { for (const tag of item.tags) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]) } else { newsMap.get(tag).push(item) } } }, new Map() ) The purpose of sliceTask is to convert ordinary tasks into coroutines. After the task has been executed a certain number of times (default is 10), it yields, giving the outer driver a chance to check timeRemaining() and decide whether to interrupt.\nThe coroutine scheduling method described above is not limited to the browser. By simulating requestIdleCallback in Node.js (similar to React\u0026rsquo;s scheduler, which is straightforward to implement), this technique can also be used for task scheduling on the server-side.\n","permalink":"https://leihuang.me/posts/time-slicing-with-coroutine/","summary":"\u003cp\u003eI wrote about \u003ca href=\"/posts/time-slicing-with-cps/\"\u003etime-slicing with CPS technique\u003c/a\u003e in the last blog post. The solution I proposed has two drawbacks:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe control over task scheduling is too weak. Task slicing relies entirely on hacking the JavaScript engine\u0026rsquo;s event loop, and it\u0026rsquo;s impossible to arbitrarily pause and resume. This makes it impossible to precisely time the slices; you can only set them based on subjective experience (the example I provided uses 500 as the interval). However, 500 tasks might still be too long, causing the main thread to be blocked for too long. Or it might be too short, not fully utilizing the current call stack.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esetTimeout\u003c/code\u003e\u0026rsquo;s timing is inaccurate, and the actual time interval will have deviations. The result is that the delays of each task accumulate, significantly increasing the total task completion time.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"an-alternative-solution-coroutine\"\u003eAn alternative solution: Coroutine\u003c/h2\u003e\n\u003cp\u003eIf a computational task can suspend itself and yield execution to other tasks, it\u0026rsquo;s a coroutine.\u003c/p\u003e","title":"Time-slicing With Coroutine"},{"content":"Background story In January this year, I applied for an overseas dev job. I was asked to finish a project as homework. The project required a ton of computations on the front end, which posed a challenge as I must ensure no operations should block the main thread. I didn\u0026rsquo;t want to move the computation to a worker thread because the data was consumed in the main thread. Serializing and de-serializing a large set of data also has a performance cost. Furthermore, to improve indexing performance, I used Map to store the results, which is not serializable.\nThe task involved is as following:\nProcess a long list of news items, and index each item according to its tags. It looks like this in code:\nconst newsList = [ { uid: \u0026#34;8be34939-bc25-4b9e-999d-2daf19fbea7b\u0026#34;, title: \u0026#34;Adipisicing do eu magna ex non est eu labore nisi duis enim elit.\u0026#34;, tags: [\u0026#34;reprehenderit\u0026#34;, \u0026#34;cupidatat\u0026#34;, \u0026#34;ad\u0026#34;, \u0026#34;ea\u0026#34;, \u0026#34;labore\u0026#34;], }, { uid: \u0026#34;488399fc-e474-4c52-a36c-625e2218fabe\u0026#34;, title: \u0026#34;Elit aute tempor dolore do sunt.\u0026#34;, tags: [\u0026#34;sint\u0026#34;, \u0026#34;ea\u0026#34;, \u0026#34;Lorem\u0026#34;, \u0026#34;consectetur\u0026#34;, \u0026#34;officia\u0026#34;], }, { uid: \u0026#34;0340b317-bd55-4c43-9982-94bf9d08b977\u0026#34;, title: \u0026#34;Aliquip qui est sint veniam consectetur.\u0026#34;, tags: [\u0026#34;sit\u0026#34;, \u0026#34;ullamco\u0026#34;, \u0026#34;consectetur\u0026#34;], }, // ... omit remaining tens of thousands of items ]; const newsMap = new Map(); newsList.forEach((news) =\u0026gt; { news.tags.forEach((tag) =\u0026gt; { if (!newsMap.has(tag)) { newsMap.set(tag, [news]); } else { newsMap.get(tag).push(news); } }); }); In practice, I\u0026rsquo;d never done massive computations on the front-end, as JavaScript is not very efficient in handling CPU-intensive work. However, after some google search, I found a way to get around this limitation. The idea is to slice a big task to many small ones and put them to different callstacks.\nTime-slicing to the rescue If you\u0026rsquo;ve been working with React long enough, you\u0026rsquo;ve probably heard of React Fiber and time-slicing. React Fiber is a new reconciliation algorithm inside of the React core. It was designed to enable React to handle computations(mostly diffing caused by setState) in a non-blocking way. When high priority tasks occur due to user inputs, React can pause low priority tasks and handle them immediately.\nThe fiber architecture is very complicated. The implementation of it is quite cryptic and daunting. Implementing a fiber algorithm in my little project would be an overkill, if not infeasible. However, I can still do time-slicing in JavaScript in an easier way.\nThe solution lies in JavaScript\u0026rsquo;s power in asynchronicity and callback functions. Encountered with asynchronous tasks, we tend to shun away from callbacks because of the dreaded \u0026ldquo;callback hell.\u0026rdquo; However, when handled properly, callbacks and asynchronicity are a good fit. The callback soup I\u0026rsquo;m about to introduce is very powerful and irreplaceable.\nIf you used to pass callbacks in Ajax programming or node.js event handlers, you already know the technique I\u0026rsquo;m going to show you. I just find a fancier name for it: CPS(Continuation-passing Style).\nWhat is CPS Here\u0026rsquo;s an identity function you would write normally:\nfunction id(x) { return x; } and here is a CPS version:\nfunction id(x, cb) { cb(x); } In continuation-passing style, instead of \u0026ldquo;returning\u0026rdquo; the procedure to its caller, you invoke the \u0026ldquo;current continuation\u0026rdquo; callback (provided by the caller) on the return value.\nThe foundation of CPS is simple:\nProcedures can take a callback to invoke upon their return value. Slice it up! The atomic operation we need to do in processing the list is as following:\nfunction indexNews(item, tag) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } } So we need to slice our previous one big task to many small tasks like the above one. Here\u0026rsquo;s how to do it:\nfunction indexNews(item, tag, continuation) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } continuation(); } function iterate(list, processTask, continuation) { function handleOne(i, j, _continuation) { if (i \u0026lt; list.length) { const item = list[i]; if (j \u0026lt; item.tags.length) { processTask(item, item.tags[j], function handleNext() { handleOne(i, j + 1, _continuation); }); } else { handleOne(i + 1, 0, _continuation); } } else { _continuation(); } } handleOne(0, 0, continuation); } iterate(newsList, indexNews, () =\u0026gt; { // Indexing is done, // we can enable features that depend on indexing safely here. console.log(\u0026#34;done\u0026#34;); }); This introduces too many recursions and makes our code way more complicated without improving performance. But we are very close!\nNotice a very important feature of the indexNews function. It takes a continuation callback and calls the continuation after finishing the current task. We\u0026rsquo;ve achieved \u0026ldquo;Inversion of Control\u0026rdquo; here. We can tell indexNews what to do in the next iteration.\nIn our case, we want it to move subsequent tasks to a new callstack so that we don\u0026rsquo;t put too much pressure on the current callstack.\nHowever, we don\u0026rsquo;t want to move every task to its own callstack, which is unnecessary.\nSo, here\u0026rsquo;s the rule:\nEach callstack can take 500 tasks, after that limit, we put the next 500 tasks in the next callstack. Repeat until all tasks are done.\nWe just need a few modifications to our previous code to achieve this:\nfunction indexNews(item, tag, continuation) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } if (indexNews.skip++ % 500 === 0) { setTimeout(continuation, 0); } else { continuation(); } } indexNews.skip = 0; Because of how event loop works in JavaScript, the setTimeout method will move its callback to the next execution callstack.\nSummary We introduced a technique we already knew and rediscovered the hidden power of it. Continuation-passing Style enables us to have control over what happens next when the current operation is completed. Relying on this feature, we first sliced a very big task to many small ones, and then chunked them into different call stacks.\nCheck out the project here .\n","permalink":"https://leihuang.me/posts/time-slicing-with-cps/","summary":"\u003ch2 id=\"background-story\"\u003eBackground story\u003c/h2\u003e\n\u003cp\u003eIn January this year, I applied for an overseas dev job. I was asked to finish a\nproject as homework. The project required a ton of computations on the front\nend, which posed a challenge as I must ensure no operations should block the\nmain thread. I didn\u0026rsquo;t want to move the computation to a worker thread because\nthe data was consumed in the main thread. Serializing and de-serializing a large\nset of data also has a performance cost. Furthermore, to improve indexing\nperformance, I used \u003ccode\u003eMap\u003c/code\u003e to store the results, which is not serializable.\u003c/p\u003e","title":"Time-slicing With Continuation-passing Style"},{"content":"Background I recently rewrote my blog website from scratch in Gatsby. This time, I didn‚Äôt use a starter template, so I had to make a lot of design decisions. When I wrote the bio section on the home page, initially I put a long heading there as a one-sentence introduction. As I was gazing at the screen, I felt something was wrong. It was too wordy. But after I took out a few words, I was not satisfied with what was left.\nAfter some trying, I came up with an idea. Why not add a typewriter to present more contents with less space? It also adds a lot of fun and dynamic to the page. It seems like legit reasoning, so I did it. I was satisfied at this time.\nA typewriter effect requires dealing with asynchronicity. I can do it in vanilla JavaScript, but the result code would be very complex, with a lot of timer events scattering around. When dealing with complex asynchronous event handling, my rule of thumb is to use tools that help me focus on the desired effects, rather than the housekeeping juggling work. RxJS stands out as my tool of choice for this role.\nWhy RxJS? RxJS enables you to encode time in values. As I see it, the greatest power of RxJS is that it enables you to encode time in values. Time becomes tangible and can be mixed and matched with other values. In the movie Arrival, an alien language can encode time in itself, so the speaker of that language is capable of foreseeing the future. RxJS is similar in a sense. When programming, you‚Äôre the dictator of all events, you already knew what will happen before you start. In RxJS, or reactive programming in a broader sense, you can encode future events in a placeholder (I try to avoid \u0026lsquo;variable\u0026rsquo; because it may be confusing for beginners) as you declare it.\nThink about the typewriter effect. What we really want is to display different texts on the screen over time. For instance, if we want to type ‚Äòhello‚Äô and then delete it, we want the texts delivered to us over time like this:\n// type h---he---hel---hell---hello // pause -------- // delete hello---hell---hel---he---h // pause -------- We can tell RxJS, ‚ÄúHey, this is the word, I want you to slice it up like this and give the pieces back to me over time.‚Äù\nEncode time in values After we have a clear vision of what we want, let‚Äôs do it and write the code!\nStart with the basics. We need to type a single word first. It‚Äôs easy.\nconst type = ({word, speed}) =\u0026gt; interval(speed).pipe( map(x =\u0026gt; word.substr(0, x + 1)), take(word.length) ) The interval source will fire up events as per the speed value we provide in milliseconds. Each time it will emit a number increasingly. When the event occurs, we map the emitted value to characters from the word. The interval timer will fire indefinitely, but we only take what we want. After passing the limit specified by the take operator, the timer will stop.\nWe also need a delete effect. Let‚Äôs add a parameter ‚Äòbackward‚Äô to the type function. We slice differently when ‚Äòbackward‚Äô is specified.\nconst type = ({word, speed, backward = false}) =\u0026gt; interval(speed).pipe( map(x =\u0026gt; backward ? word.substr(0, word.length - x - 1) : word.substr(0, x + 1) ), take(word.length) ) To combine the type-pause-delete-pause effects together, we need the concat operator to concatenate 4 event sources (we\u0026rsquo;ll call them observables from now on)\nconst typeEffect = word =\u0026gt; concat( type({word, speed: 70}), // type of(\u0026#39;\u0026#39;).pipe(delay(1500), ignoreElements()), // pause type({word, speed: 30, backward: true}), // delete of(\u0026#39;\u0026#39;).pipe(delay(300), ignoreElements()) // pause ) We type and delete at different speeds. And also pause differently after typing and deleting. For pausing effect, we emit an empty string and delay the event. ignoreElements operator just ignore emmited values. This is to only encode time itself and discard any values.\nThen we move on to type multiple words. Using the from operator, we can turn an array into an observable, which is a term to describe \u0026ldquo;values over time\u0026rdquo;. After this, we know RxJS will feed us the items in the array over time. But how frequently? In what form? We‚Äôll tell RxJS in the pursuing operators.\nconst value = useObservable(() =\u0026gt; from(words).pipe(concatMap(typeEffect), repeat()) ) useObservable is a helper function to turn values emitted from observables into React state.\nwe use concatMap to map every word into a new observable and concatenate them. Say we feed RxJS value [‚Äòhello‚Äô, ‚Äòhow are you‚Äô, ‚Äòbye‚Äô ], in a diagram, it will look like this:\n----typeEffect(‚Äòhello‚Äô) ----typeEffect(‚Äòhow are you‚Äô)---typeEffect(‚Äòbye‚Äô)--- The repeat operator tells RxJS to repeat the source observable forever.\nThat\u0026rsquo;s all the code you need to build a typewriter effect!\nHere is a fun demo:\n","permalink":"https://leihuang.me/posts/typewritter-in-rxjs/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently rewrote my blog website from scratch in Gatsby. This time, I didn‚Äôt\nuse a starter template, so I had to make a lot of design decisions. When I wrote\nthe bio section on the home page, initially I put a long heading there as a\none-sentence introduction. As I was gazing at the screen, I felt something was\nwrong. It was too wordy. But after I took out a few words, I was not satisfied\nwith what was left.\u003c/p\u003e","title":"Typewriter Effect With RxJS"},{"content":"Recently, I encountered a situation where I need to perform text searches in a large set of data. Normally, I would do it in a filter function, but that would be slow when the list is too long. There\u0026rsquo;s a data structure for this situation. Meet the Trie!\nTrie (pronounced try) is a tree-like data structure that\u0026rsquo;s created for efficient text searches.\nHow does it work Trie takes all words and rearranges them in a tree hierarchy. For example, the list of words ['abet', 'abode', 'abort'] will be transformed into a structure like this:\n--------------- a | b / \\ e o | / \\ t d r | | e t After that, if we want to search for a word beginning with \u0026lsquo;abo\u0026rsquo;, we can skip the branch under e in the third level.\nIn this post, I\u0026rsquo;m going to walk you through the details of implementing a Trie. There\u0026rsquo;ll be a lot of code. It may be intimidating and boring as hell, but I\u0026rsquo;ll add comments at each key step.\nImplementing a Trie in JavaScript 1. Node information class TrieNode { constructor(char) { this.char = char // to store the current character this.validWord = false // if the current character is at the end of a whole word this.parent = null // parent of the current node this.children = [] // children nodes } } 2. Adding a word to a Trie First, we need a method to add a new word into a Trie:\nclass Trie { constructor() { this.root = new TrieNode(\u0026#39;\u0026#39;) } add(word) { let current = this.root // The searching pointer starts at the root. for (let i = 0; i \u0026lt; word.length; i += 1) { const ch = word[i] let found = false // Iterating through the children nodes of the current node for (let j = current.children.length; j--; ) { const child = current.children[j] if (child.char === ch) { found = true // If we find a matching character, move the pointer to the matching child current = child break } } // If we can\u0026#39;t find the character in the child node list, create a new node, and add it into the list if (!found) { current.children.push(new TrieNode(ch)) const newNode = current.children[current.children.length - 1] newNode.parent = current // Move the pointer to the newly created node current = newNode } } // After the above operations, the pointer should be at the end of a word current.validWord = true } } 3. Deleting a word from a Trie We also need a method to remove a word from a Trie.\ndelete(word) { let current = this.root; for (let i = 0; i \u0026lt; word.length; i += 1) { const ch = word[i]; let found = false; for (let j = current.children.length; j--; ) { const child = current.children[j]; if (child.char === ch) { found = true; current = child; break; } } if (!found) { // If a character of a word can\u0026#39;t be found in the children list, then we know the word is not in the Trie return; } } // After the for loop, the pointer should be at the end of the word to be deleted current.validWord = false; let stop = false; while (!stop) { if ( current.children.length === 0 \u0026amp;\u0026amp; !current.validWord \u0026amp;\u0026amp; current.parent ) { // Operate on the parent nodes at every level upwards const { parent } = current; const childIndex = parent.children.indexOf(current); const end = parent.children.length - 1; // Swap the position of the current node and the node at the end of the list. [parent.children[childIndex], parent.children[end]] = [ parent.children[end], parent.children[childIndex] ]; // Now, the node to be deleted should be at the end of the list, we just need to pop it out parent.children.pop(); // Move the pointer upwards current = parent; } else { stop = true; } } } 4. Searching for a word Before I tried to implement Trie, I\u0026rsquo;d read a lot of tutorials on this topic. Almost none of these tutorials implements full search functionality. For example, this tutorial on GeeksForGeeks implements a search method that only checks if a word is in a Trie.\nWhen we search for a word, we need to know all the related words as we type in. Here\u0026rsquo;s how to achieve this:\nsearch(input) { // inputMirror is not required. I just want the output to match the input exactly. // Otherwise, if you input Fa, the returned text would be fa const inputMirror = []; let current = this.root; for (let i = 0; i \u0026lt; input.length; i += 1) { const ch = input.charAt(i); let found = false; for (let j = current.children.length; j--;) { const child = current.children[j]; if (child.char.toLowerCase() === ch.toLowerCase()) { found = true; current = child; inputMirror.push(child.char); break; } } if (!found) { return []; } } // After the above operations, the pointer should be at the node corresponding // to the last input character const match = []; // to store all matching words const tracker = []; // keep track of found character nodes function traverse(node) { tracker.push(node.char); if (node.validWord) { const temp = inputMirror.slice(0, input.length - 1); temp.push(...tracker); match.push(temp.join(\u0026#39;\u0026#39;)); } // Recursively call all children nodes node.children.forEach(traverse); // The function that comes last to the recursion stack will be the first to execute the following command. //Since we are at the end of a Trie, we start to empty the tracker at every level upwards. // For example, when you type in fa, after matching the word \u0026#39;fabric\u0026#39;, // the tracker will contain [\u0026#39;b\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;k\u0026#39;]. // Starting from \u0026#39;k\u0026#39;, we pop out every character upwards, so that when we start to match the word \u0026#39;face\u0026#39;, the tracker is empty. tracker.pop(); } traverse(current); return match; } Limitations The implementation I just showed you is not optimal. To make it efficient, we still need to do a lot of work. For example, we can store the characters in a Binary Search Tree, so that we can search them more efficiently.\nIdeally, the time complexity of a Trie search would be M * log N, where log N is the time complexity of a binary search, M is the length of the input string.\nAnother limitation of a Trie is that building a Trie consumes a lot of memory since a Trie needs to maintain a lot of reference between nodes. If the task at hand is memory sensitive, we can use Ternary Search Tree to do a better job.\nCheck out the complete code here\n","permalink":"https://leihuang.me/posts/implementing-tri/","summary":"\u003cp\u003eRecently, I encountered a situation where I need to perform text searches in a\nlarge set of data. Normally, I would do it in a \u003ccode\u003efilter\u003c/code\u003e function, but that\nwould be slow when the list is too long. There\u0026rsquo;s a data structure for this\nsituation. Meet the Trie!\u003c/p\u003e\n\u003cp\u003eTrie (pronounced try) is a tree-like data structure that\u0026rsquo;s created for efficient\ntext searches.\u003c/p\u003e\n\u003ch2 id=\"how-does-it-work\"\u003eHow does it work\u003c/h2\u003e\n\u003cp\u003eTrie takes all words and rearranges them in a tree hierarchy. For example, the\nlist of words \u003ccode\u003e['abet', 'abode', 'abort']\u003c/code\u003e will be transformed into a structure\nlike this:\u003c/p\u003e","title":"Implementing A Trie In JavaScript"},{"content":"When I was reading Eric Elliott's article on Lenses , I was curious about how such beautiful magic can be fully implemented in JavaScript. It was a tough exploration. Many of the tutorials online are about Haskell, which cannot be easily translated to JavaScript. I read the source code of Ramda and finally grokked how it works.\nIn order to understand lenses, you need to first understand some prerequisite functional programming concepts. I‚Äôll walk you through the essential ones.\nCurrying Currying is a technique that you use to delay function execution. It enables you to feed a function one argument at a time. For example, with function const add = (x, y) =\u0026gt; x + y, you need to feed the function two numbers at once in order to perform the calculation. What if we only have the first argument value available and want to store it in the add function context, and later call it when we‚Äôre ready? Like this:\nconst add = (x, y) =\u0026gt; x + y; // we get a value v from somewhere, and we want to store it in the add function context const addV = add(v); // and later we get a value w, we can finally perform the addition addV(w); The example is trivial, but you get the idea. Why do we want to store a value inside the context of a function? This is how we combine value with behaviors in functional programming. You‚Äôll see what I mean once we get to the lens part.\nHere‚Äôs how we implement currying in JavaScript:\nconst curry = (fn) =\u0026gt; (...args) =\u0026gt; args.length \u0026gt;= fn.length ? fn(...args) : curry(fn.bind(undefined, ...args)); Functors Functors are just data types that you can map over. Think about JavaScript array, you can map over an array and transform the values inside of it. Functors are similar, they are ‚Äòboxes‚Äô that hold computational context. Let‚Äôs see a few examples:\nconst Box = (x) =\u0026gt; ({ value: x, map: (f) =\u0026gt; Box(f(x)), }); Box is a functor. We can‚Äôt see what use it has yet. But let‚Äôs observe some properties of it.\nWhen you call Box with a value, the value is stored in a context, which is the returned object. After that, you can transform the value by mapping over the context however you want.\nBox(2) .map((x) =\u0026gt; x + 1) .map((x) =\u0026gt; x * 2); We are stacking up computations by mapping. That‚Äôs all we need to know about functors for now.\nImplementing lenses Let‚Äôs put what we just learned into use and implement lenses!\nFirst, we define functional getters and setters. They‚Äôre pretty simple.\nconst prop = curry((k, obj) =\u0026gt; (obj ? obj[k] : undefined)); const assoc = curry((k, v, obj) =\u0026gt; ({ ...obj, [k]: v })); const obj = {a: 1, b: 2}; prop(‚Äòa‚Äô)(obj) // 1 assoc(a)(3)(obj) // {a: 3, b: 2} Then we define a function to make lenses:\nconst makLens = curry( (getter, setter) =\u0026gt; (functor) =\u0026gt; (target) =\u0026gt; functor(getter(target)).map((focus) =\u0026gt; setter(focus, target)) ); I know how you feel about this cryptic function. Just ignore it, for now. We‚Äôll come back to it when we‚Äôre ready.\nLet‚Äôs simplify the makeLens function a bit and make the getter and setter ready:\nconst lensProp = (k) =\u0026gt; makeLens(prop(k), assoc(k)); Here come the mighty functors:\nconst getFunctor = (x) =\u0026gt; Object.freeze({ value: x, map: (f) =\u0026gt; getFunctor(x), }); const setFunctor = (x) =\u0026gt; Object.freeze({ value: x, map: (f) =\u0026gt; setFunctor(f(x)), }); You can see they are very similar as the Box functor we‚Äôve defined earlier. We use Object.freeze() to prevent mutations, as mutations in functional programming are forbidden.The getFunctor just ignores the mapping function and always returns the initial value, seems like very silly.\nNow, we‚Äôre finally ready to make something useful!\nconst view = curry((lens, obj) =\u0026gt; lens(getFunctor)(obj).value); const sample = { foo: { bar: { ha: 6 } } }; const lensFoo = lensProp(\u0026#34;foo\u0026#34;); view(lensFoo, sample); // =\u0026gt; {bar: {ha: 6}} Yay! After so much cryptic code, we are finally able to get a value out from an object! ü§£\nBefore we continue, let‚Äôs reason about the above code.\nWhen we call lens with getFunctor, and later call getFunctor with a value pulled out by the getter function provided earlier, we get a very simple computational context. In the case of getFunctor, this context just provides the initial value and ignores mapping operations later.\nLet‚Äôs look at set operations:\nconst over = curry((lens, f, obj) =\u0026gt; lens((y) =\u0026gt; setFunctor(f(y)))(obj).value); const always = (a) =\u0026gt; (b) =\u0026gt; a; const set = curry((lens, val, obj) =\u0026gt; over(lens, always(val), sample)); set(lensFoo, 5, sample); // =\u0026gt; {foo: 5} This time, the setFunctor doesn‚Äôt ignore mapping operations, so the operation map(focus =\u0026gt; setter(focus, target)) from the makeLens function will be performed, giving us the opportunity to transform the value returned by the getter function.\nThe always function looks silly, but look at how we use it to implement set, it‚Äôs a useful one!\nThe power of lenses Based on the examples I gave earlier, it‚Äôs not obvious how useful lenses can be. In JavaScript, we can read and set values in objects very easily. It seems like there‚Äôs no need for all the hassles!\nThe power of lenses comes from their composability. Let‚Äôs first define a compose function:\nconst compose = (...fns) =\u0026gt; (args) =\u0026gt; fns.reduceRight((x, f) =\u0026gt; f(x), args); Then we can read the inner values of the sample object like this:\nconst lensFoo = lensProp(\u0026#34;foo\u0026#34;); const lensBar = lensProp(\u0026#34;bar\u0026#34;); const lensFooBar = compose(lensFoo, lensBar); view(lensFooBar, sample); // =\u0026gt; {ha: 6} We can write a helper function to help us to get the inner lens:\nconst lensPath = (path) =\u0026gt; compose(...path.map(lensProp)); const lensHa = lensPath([\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;ha\u0026#34;]); const add = (a) =\u0026gt; (b) =\u0026gt; a + b; view(lensHa, sample); // =\u0026gt; 6 over(lensHa, add(2), sample); // =\u0026gt; {foo: {bar: {ha: 8}}} Ok, I know you must be thinking: how‚Äôs this powerful? I can achieve the same thing using lodash _.get()! Stay patient!\nLet‚Äôs consider another example. Say we have an app that lets users log their body weight. Users can fill in with both killograms and pounds. To avoid data redundancy, we only stores user records in killograms. Here\u0026rsquo;s a user record:\nconst user = { weightInKg: 65 }; We know that we have the following conversion rate between kg and lb:\nconst kgToLb = (kg) =\u0026gt; 2.20462262 * kg; const lbToKg = (lb) =\u0026gt; 0.45359237 * lb; If we want to display the user\u0026rsquo;s weight in pounds, we can get the weight in kg, and convert it to lb, which is a very straightforward approach. But we can do it more smoothly with lenses:\nconst weightInKg = lensProp(\u0026#34;weightInKg\u0026#34;); const lensLb = lens(kgToLb, lbToKg); const inLb = compose(lensLb, weightInKg); view(inLb, user); // -\u0026gt; 143.3 This looks neat. We provide different lenses to the view function, it will return us a tailored result, and the target data remains untouched.\nSuppose that the user one day adds 5 pounds to his record, the data can be updated easily like this:\nover(inLb, add(5), user); // -\u0026gt; 67.27 Wow! That reads like plain English. Without digging into the implementation details, we can interpret the operation as this: under this lens, I want to add 5 to the user record. I don\u0026rsquo;t care in what unit the stored data may be, just do it for me! The power of declarative programming really shines in this example.\n","permalink":"https://leihuang.me/posts/lens-in-js/","summary":"\u003cp\u003eWhen I was reading \n\n\u003ca href=\"https://medium.com/javascript-scene/lenses-b85976cb0534\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\n  Eric Elliott's article on Lenses\n  \u003csvg\n    xmlns=\"http://www.w3.org/2000/svg\"\n    width=\"16\"\n    height=\"16\"\n    viewBox=\"0 0 24 24\"\n    fill=\"none\"\n    stroke=\"currentColor\"\n    stroke-width=\"2\"\n    stroke-linecap=\"round\"\n    stroke-linejoin=\"round\"\n    class=\"external-icon\"\n  \u003e\n    \u003cpath d=\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"\u003e\u003c/path\u003e\n    \u003cpolyline points=\"15 3 21 3 21 9\"\u003e\u003c/polyline\u003e\n    \u003cline x1=\"10\" y1=\"14\" x2=\"21\" y2=\"3\"\u003e\u003c/line\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e,\nI was curious about how such beautiful magic can be fully implemented in\nJavaScript. It was a tough exploration. Many of the tutorials online are about\nHaskell, which cannot be easily translated to JavaScript. I read the source code\nof Ramda and finally grokked how it works.\u003c/p\u003e","title":"Introduction to Lenses in JavaScript"},{"content":"I came across this article (written in Chinese) the other day. It was about parabolic curve animation in vanilla JS. I wondered how RxJS can implement this. Below is the result of my investigation.\nImagine we take a perspective from a slow-motion camera. What humans see as a smooth animation is just an object that is put at different places at every fragment of a time period. This can be expressed as a \u0026lsquo;stream\u0026rsquo; of object position. The mechanism of an animation can be simplified by somehow mapping every fragment of a time period to a position point in space. In practice, time cannot be fragmented indefinitely, what we want is an approximation of an \u0026ldquo;atomic time unit\u0026rdquo;. The browser has provided us a tool to achieve this, which is the requestAnimationFrame API.\nWe can map every timestamp emitted by requestAnimationFrame to a position coordinate at the screen. Let\u0026rsquo;s see how we can do this in Rxjs!\nGenerating time sequence // I only demonstrate the import part once, // they will be omitted in later code. import { interval, animationFrameScheduler, fromEvent, defer, merge, } from \u0026#34;rxjs\u0026#34;; import { map, takeWhile, tap, flatMap } from \u0026#34;rxjs/operators\u0026#34;; function duration(ms) { return defer(() =\u0026gt; { const start = Date.now(); return interval(0, animationFrameScheduler).pipe( map(() =\u0026gt; (Date.now() - start) / ms), takeWhile((n) =\u0026gt; n \u0026lt;= 1) ); }); } What defer does is to only create a new observable upon being subscribed. This is to ensure every subscriber gets a new observable, otherwise, we\u0026rsquo;ll see weird movements.\nFirst, we record the animation beginning time, then we return an interval function that will emit an event every 0 seconds. This seems ridiculous. However, notice the animationFrameScheduler, it schedules at which point the interval function can emit an event. This is how we simulate an atomic time unit. The map function maps every time unit emitted by interval to a time ratio of current elapse to the whole animation duration. takeWhile ensures we unsubscribe to interval once we reach the end. We know we\u0026rsquo;ve reached the end if the current elapse equals the total time.\nThen we calculate how far the object is away from the origin at every point in time.\nMove the object const distance = (d) =\u0026gt; (t) =\u0026gt; d * t; d is the total distance the object is going to move. t is the time ratio, which has been calculated in the last step. We multiply them and get the distance at that point.\nWe get the target in the DOM and move it.\nconst targetDiv = document.querySelector(\u0026#34;.target\u0026#34;); const moveRight$ = duration(1500).pipe( map(distance(1000)), tap((x) =\u0026gt; (targetDiv.style.left = x + \u0026#34;px\u0026#34;)) ); const moveDown$ = duration(900).pipe( map(distance(700)), tap((y) =\u0026gt; (targetDiv.style.top = y + \u0026#34;px\u0026#34;)) ); The first stream moves the object to the right, the second to the bottom. Notice that the animation hasn\u0026rsquo;t taken place, because we haven\u0026rsquo;t\u0026rsquo; subscribed to them yet.\nWe combine these two streams into a new stream, making the object move rightwards and downwards at the same time.\nmerge(moveRight$, moveDown$).subscribe(); This is boring, we don\u0026rsquo;t see any curve yet. But bear with me.\nMake the motion trajectory parabolic! I hope you still remember middle school math. If you don\u0026rsquo;t, fret not. It\u0026rsquo;s pretty intuitive actually. What we observe as a curve movement is the result of an object moves at different speeds in different directions. The shape of the curve can be expressed in a mathematical equation. Take a look of the graph of the equation y = x^3, the left and right half of it is the parabolic curve we want: If we can make the downward speed and rightward speed form a cubic equation, then we have a parabolic curve movement!\nWe can use two different easing functions that form a cubic relationship between them:\nThe first one is easeInQuadÔºö\nconst easeInQuad = (t) =\u0026gt; t * t; The second one is easeInQuintÔºö\nconst easeInQuint = (t) =\u0026gt; Math.pow(t, 6); Then we only need to map the time ratio emitted from the interval pipeline to the result of applying these easing functions:\nconst moveDown$ = duration(900).pipe( map(easeInQuint), map(distance(700)), tap((y) =\u0026gt; (targetDiv.style.top = y + \u0026#34;px\u0026#34;)) ); const moveRight$ = duration(1500).pipe( map(easeInQuad), map(distance(1000)), tap((x) =\u0026gt; (targetDiv.style.left = x + \u0026#34;px\u0026#34;)) ); See the codepen below for the result and the complete code:\nSee the Pen{' '} Rx .js parabola animation{' '} by Lei (@leihuang) on{' '} CodePen. ","permalink":"https://leihuang.me/posts/curve-animation-in-js/","summary":"\u003cp\u003eI came across \n\n\u003ca href=\"https://juejin.im/post/5bb0b7fae51d450e62380ef3\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\n   this article (written in Chinese)\n  \u003csvg\n    xmlns=\"http://www.w3.org/2000/svg\"\n    width=\"16\"\n    height=\"16\"\n    viewBox=\"0 0 24 24\"\n    fill=\"none\"\n    stroke=\"currentColor\"\n    stroke-width=\"2\"\n    stroke-linecap=\"round\"\n    stroke-linejoin=\"round\"\n    class=\"external-icon\"\n  \u003e\n    \u003cpath d=\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"\u003e\u003c/path\u003e\n    \u003cpolyline points=\"15 3 21 3 21 9\"\u003e\u003c/polyline\u003e\n    \u003cline x1=\"10\" y1=\"14\" x2=\"21\" y2=\"3\"\u003e\u003c/line\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e the other day. It was about parabolic curve animation in vanilla JS. I\nwondered how RxJS can implement this. Below is the result of my\ninvestigation.\u003c/p\u003e\n\u003cp\u003eImagine we take a perspective from a slow-motion camera. What humans see as a\nsmooth animation is just an object that is put at different places at every\nfragment of a time period. This can be expressed as a \u0026lsquo;stream\u0026rsquo; of object\nposition. The mechanism of an animation can be simplified by somehow mapping\nevery fragment of a time period to a position point in space. In practice, time\ncannot be fragmented indefinitely, what we want is an approximation of an\n\u0026ldquo;atomic time unit\u0026rdquo;. The browser has provided us a tool to achieve this, which is\nthe \u003ccode\u003erequestAnimationFrame\u003c/code\u003e API.\u003c/p\u003e","title":"Parabolic Curve Animation With RxJS"}]