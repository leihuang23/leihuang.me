[{"content":"The proliferation of AI (specifically LLMs) has been the major development in our industry recently. Many people are understandably impressed by the capabilities of cutting-edge LLMs. However, the hype sometimes becomes ridiculous. On Twitter, I\u0026rsquo;ve seen people claiming AGI is already here because some LLMs are capable of solving very advanced coding challenges.\nI\u0026rsquo;ve been using LLMs at work for quite a while. Although it\u0026rsquo;s not rare for me to use them to generate code beyond my expertise, I remain convinced that current LLMs lack genuine cognitive capabilities. The notion of fully delegating human tasks to AI systems remains unrealistic today. I doubt whether it will ever be truly possible.\n1. It has no expertise Let me start with a very recent example. GPT-4.1 was out this week. Here\u0026rsquo;s what OpenAI says about it:\nGPT‑4.1 scores 54.6% on SWE-bench Verified, improving by 21.4%abs over GPT‑4o and 26.6%abs over GPT‑4.5—making it a leading model for coding.\nI recently developed a hobby project Kakashi. I wanted to conditionally enable a button for local development — a trivial task, but one I was reluctant to handle manually. So I asked GPT-4.1 to do it:\nLei: Only enable the image uploading functionality in local dev mode. Make the \u0026lsquo;upload image\u0026rsquo; button dynamically injected with js GPT-4.1: To enable image uploading only in local development mode and inject the \u0026ldquo;Upload Image\u0026rdquo; button dynamically, you can:\nDetect local development (e.g., window.location.hostname is localhost or 127.0.0.1). Dynamically create and insert the \u0026ldquo;Upload Image\u0026rdquo; button and file input in JS. Only attach related event listeners if in dev mode. Here\u0026rsquo;s how you can modify your code:\nif ( window.location.hostname === \u0026#34;localhost\u0026#34; || window.location.hostname === \u0026#34;127.0.0.1\u0026#34; ) \u0026hellip;\nLei: Wait, there\u0026rsquo;s a better way to do it. We can use build-time variables. We only need to omit this functionality when building. GPT-4.1: You\u0026rsquo;re correct! The best practice is to use a build-time variable (such as process.env.NODE_ENV or a custom Vite/webpack define) to conditionally include the image upload functionality. This way, the code is omitted from production bundles entirely.\nHere\u0026rsquo;s how you can do it using a build-time variable (e.g., import.meta.env.DEV for Vite, or process.env.NODE_ENV for webpack):\n// Only inject upload button in dev mode if (import.meta.env.DEV) { // Dynamically create upload button } This conversation reveals a lot about the nature of LLMs.\nFundamentally, what LLMs do is generate the right words at the right time. They do this by sampling texts from the internet and placing every token into hyperspace (represented by vectors). When you have conversations with LLMs, they try to complete a \u0026ldquo;user - system\u0026rdquo; conversation with statistically probable text.\nIn the conversation above, GPT gave the initial answer probably because it saw such an answer during training.(It\u0026rsquo;s also possible the LLM was \u0026ldquo;thinking\u0026rdquo;, i.e. generating its working memory, with bad content) It failed to discriminate bad solutions from good ones.\nWhy did GPT initially propose an inferior solution? Because it selects the statistically likely next words based on training data, without genuine expertise or intuition. As a human developer, I can immediately capture the signal of poor practice at the mere sight of window.location.hostname. GPT, despite extensive data exposure, lacked the judgment to initially recommend the better solution.\n2. It doesn\u0026rsquo;t know what is impossible The limitation of an LLM’s ability to mimic \u0026ldquo;understanding\u0026rdquo; quickly manifests when tackling very complex problems, such as computer vision.\nThe Kakashi app collects users\u0026rsquo; drawing paths as coordinates and animates them using Fourier Transformation. The animation is as good as how well the user draws. My drawing isn\u0026rsquo;t very good, so I wanted to generate animation paths from existing one-stroke drawings, like this one: Here\u0026rsquo;s a conversation between me and Claude 3.7 with extended \u0026ldquo;thinking\u0026rdquo;:\nLei: I want to build a web app to extract coordinate points from images so that I can animate the coordinates later. Here are the ideas:\nWe can assume the images will only contain one-stroke drawing. Our goal is to extract this one-stroke drawing. The image will not be guaranteed to have perfect white background. We\u0026rsquo;ll need to deal with noise. We can start with getting rid of any rogue elements/pixels on the image and then extracting the main path. We also need to handle potential breaks of the path. If there are breaks, we need to fill them. Then we make the path a one pixel wide smooth line. Be careful not to make the path wiggly. Find the start and end point of the stroke. We need to sample the path points as if we are drawing. I don\u0026rsquo;t have a good idea on how long the draw should be, as the drawings can have different complexities. Make the default draw duration 4 seconds, but make it a variable that the user can provide through the UI. The idea is that we sample the points within the browser animation rate limit. So the frequency should be one pixel per duration_in_ms/16.67. We also need to mimic human drawing gesture. Faster in straight parts, slower in curvy parts. When deciding the start and end point, follow the rule that start from left, end on the right. I know this project is very complex. Use WebAssembly and Rust if it would be easier. Many steps can go wrong, so I want comprehensive debug info. Render intermediate image data on a debug canvas if you can. The extracted coordinates are calculated relative to the left top corner of the image. Start with presenting a button that the user can use to upload an image. Are these instructions clear to you? Be sure you understand them all. Improve my flow if you can.\nClaude 3.7: Your requirements for the image coordinate extraction web app are clear. This is an interesting project! Let me understand and improve your approach.\nBlah blah\u0026hellip;\nClaude confidently gave a non-solution. It didn\u0026rsquo;t work, of course. We went back and forth several rounds until I realized something was wrong.\nLei: It still doesn\u0026rsquo;t work. I think you are trying in the wrong direction. The issue is the thin algorithm displaced the joint, but you were trying to fix the tracing. Claude 3.7: I understand the problem now - you\u0026rsquo;re absolutely right. The issue is with the thinning algorithm, not the path tracing. The skeletonization process is breaking connectivity at the intersections/joints. Let me fix the actual problem:\n\u0026hellip;\nBlah blah\nBroken code, again.\nSuddenly, I had a Eureka moment and felt smart:\nLei: I have an intuition. The problem is the thin algorithm can\u0026rsquo;t handle intersections. Try a different approach. Let\u0026rsquo;s follow the drawing path from start to finish and thin the line to one pixel as we traverse. And Claude was quick to acknowledge that I was helpful:\nClaude 3.7: You\u0026rsquo;ve hit the nail on the head! Following the actual drawing path rather than relying on thinning algorithms is exactly what we need. Let me implement this approach:\n\u0026hellip;\nAnd of course, broken code again. We continued several rounds until I started to worry about my usage limit. Then, I started a new conversation and changed the question:\nLei: You are not solving the problem. I\u0026rsquo;ve already told you the thin algorithm handles the cross wrong. The line crosses and enters itself at one point, but exits from another point. I\u0026rsquo;ve added the screenshot. Is this problem even possible to solve? How do you implement a perfect cross?\nClaude 3.7: You\u0026rsquo;re absolutely right, and I apologize for not addressing the specific issue. Looking at your screenshot, I can see the exact problem - when a line crosses itself in a 2D image, there\u0026rsquo;s an inherent ambiguity about which path to follow.\nThis is actually a fundamental challenge in computer vision known as the \u0026ldquo;crossing problem.\u0026rdquo; When a line crosses itself in a 2D image, we lose information about which path was drawn on top (the z-order). The flattened 2D representation doesn\u0026rsquo;t preserve this crucial information.\nIs this problem even possible to solve? Theoretically, no - not with 100% accuracy from a single 2D image without additional information. This is an inherently ambiguous situation.\nHowever, we can implement approaches that make intelligent guesses:\n\u0026hellip;\nOnly after burning through most of my daily usage limit did Claude finally tell me the truth, and even then, it had the gall to keep offering ineffective solutions.\nMy human agency kicked in again. Perhaps I could draw on the image to guide the tracing direction?\nBut by then, I knew Claude couldn\u0026rsquo;t help. Without expertise in computer vision, I\u0026rsquo;d likely waste more time.\n3. It doesn\u0026rsquo;t know you\u0026rsquo;re asking a dumb question LLMs behave like some tech bros and crypto bros — always 100% sure and convincing.\nI sometimes fall for their confidence and overestimate their abilities.\nMy handwriting isn\u0026rsquo;t great, so I thought AI could improve it. After collecting my handwriting coordinates, I asked Gemini 2.5 Pro for improvement.\nLei: I have a coordinates path that represents a one-stroke path of the text \u0026ldquo;Hello\u0026rdquo;. My handwriting is ugly and I want you to improve it. Give me a more stylish one-stroke path. Here\u0026rsquo;s the js array for my current path:\n[coordinates]\nGemini Pro 2.5: Okay, I can help you with that! Creating a \u0026ldquo;stylish\u0026rdquo; path is subjective, but I can generate a new set of coordinates representing a smoother, more flowing cursive style for \u0026ldquo;Hello\u0026rdquo; in a single stroke.\n\u0026hellip;\n(Blah blah enthusiastic and self-assured rubbish)\nOf course, Gemini couldn\u0026rsquo;t help — the coordinates I provided never appeared on the internet and pattern-matching was doomed to fail. Unless Gemini wrote a dedicated program to deterministically improve my handwriting, there was no way it could help me. Yet, Gemini confidently provided rubbish coordinates.\nWe continued until I realized I\u0026rsquo;d asked a dumb question.\nA human expert would quickly identify a bad question and help directing you to ask the right one. But LLM isn\u0026rsquo;t capable of that. It\u0026rsquo;ll always mimic a conversation, even when it\u0026rsquo;s clearly out of its depth.\n","permalink":"https://leihuang.me/posts/ai-has-no-understanding/","summary":"\u003cp\u003eThe proliferation of AI (specifically LLMs) has been the major development in our industry recently. Many people are understandably impressed by the capabilities of cutting-edge LLMs. However, the hype sometimes becomes ridiculous. On Twitter, I\u0026rsquo;ve seen people claiming AGI is already here because some LLMs are capable of solving very advanced coding challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ve been using LLMs at work for quite a while. Although it\u0026rsquo;s not rare for me to use them to generate code beyond my expertise, I remain convinced that current LLMs lack genuine cognitive capabilities. The notion of fully delegating human tasks to AI systems remains unrealistic today. I doubt whether it will ever be truly possible.\u003c/p\u003e","title":"AI Has No Understanding"},{"content":"I was reviewing my old notebook and came across a piece of code that I took from somewhere many years ago. I asked Claude 3.7 Sonnet about this code, and here\u0026rsquo;s the conversation:\nLei: Take a look at the following code:\nlet timeout = null; const queue = new Set(); function process() { for (const task of queue) { task(); } queue.clear(); timeout = null; } function enqueue(task) { if (timeout === null) timeout = setTimeout(process, 0); queue.add(task); } I\u0026rsquo;m not sure how is this code useful. One scenario I can think of is modifying the DOM. Doing DOM manipulation in one batch might avoid reflow. But I\u0026rsquo;m fuzzy on details. Can you give me a concrete example?\nAssistant: You\u0026rsquo;re right that this code is implementing a task queue with batched processing, which is a common pattern in front-end development to optimize DOM manipulations. Let me explain how this works and provide a concrete example.\nThe code you\u0026rsquo;ve shared implements a simple task batching mechanism:\nenqueue() adds tasks to a queue If there\u0026rsquo;s no pending timeout, it schedules processing to occur on the next event loop tick (via setTimeout(process, 0)) When process() runs, it executes all queued tasks at once and clears the queue Here\u0026rsquo;s a concrete example of how this would be useful for DOM manipulation:\n// Our task queue implementation (your code) let timeout = null; const queue = new Set(); function process() { for (const task of queue) { task(); } queue.clear(); timeout = null; } function enqueue(task) { if (timeout === null) timeout = setTimeout(process, 0); queue.add(task); } // Example usage for DOM updates function updateElement(id, property, value) { enqueue(() =\u0026gt; { document.getElementById(id).style[property] = value; }); } // Without batching, these would cause separate reflows updateElement(\u0026#34;header\u0026#34;, \u0026#34;height\u0026#34;, \u0026#34;60px\u0026#34;); updateElement(\u0026#34;sidebar\u0026#34;, \u0026#34;width\u0026#34;, \u0026#34;250px\u0026#34;); updateElement(\u0026#34;content\u0026#34;, \u0026#34;margin\u0026#34;, \u0026#34;20px\u0026#34;); updateElement(\u0026#34;footer\u0026#34;, \u0026#34;padding\u0026#34;, \u0026#34;15px\u0026#34;); The benefit here is that if you call updateElement() multiple times in quick succession, all DOM modifications will be batched into a single update that happens on the next event loop tick. The browser only needs to perform layout calculations once after all updates are applied, rather than after each individual update.\nThis pattern is similar to how React\u0026rsquo;s setState() batches state updates or how Vue.js handles reactivity. It\u0026rsquo;s particularly valuable when:\nYou\u0026rsquo;re making many small DOM changes that would otherwise trigger multiple reflows You want to ensure a consistent visual state (all changes appear simultaneously) You\u0026rsquo;re responding to high-frequency events like scrolling or resizing The task queue pattern is also useful beyond DOM manipulation - it can batch API calls, logging operations, or any type of work where grouping operations is more efficient than executing them immediately.\nLei: Explain how it\u0026rsquo;s useful for batching API calls. Assistant: The task queue pattern is very useful for batching API calls, which can provide several important benefits. Here\u0026rsquo;s how it works in that context:\n// The original queue implementation let timeout = null; const queue = new Set(); function process() { for (const task of queue) { task(); } queue.clear(); timeout = null; } function enqueue(task) { if (timeout === null) timeout = setTimeout(process, 0); queue.add(task); } // API call batching example const pendingUpdates = {}; function scheduleUserUpdate(userId, fieldName, value) { // Initialize or get the update object for this user if (!pendingUpdates[userId]) { pendingUpdates[userId] = {}; // Schedule this user\u0026#39;s batch update enqueue(() =\u0026gt; { // When processed, send the accumulated changes for this user const userData = pendingUpdates[userId]; delete pendingUpdates[userId]; // Single API call with all field updates apiClient.updateUser(userId, userData); }); } // Add this field update to the pending batch pendingUpdates[userId][fieldName] = value; } // Usage - all these will be combined into a single API call scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;John Smith\u0026#39;); scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;email\u0026#39;, \u0026#39;john@example.com\u0026#39;); scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;preferences\u0026#39;, { theme: \u0026#39;dark\u0026#39; }); The benefits of batching API calls like this include:\nReduced network overhead: Instead of making multiple separate HTTP requests, you make one request with consolidated data, reducing latency and server load.\nPreventing race conditions: When multiple parts of your application update the same resource, batching ensures all changes are applied atomically rather than potentially overwriting each other.\nRate limit management: If an API has rate limits, batching helps you stay under those limits by combining multiple logical operations into fewer actual requests.\nImproved user experience: For operations that might trigger UI indicators (like saving status), batching prevents flickering or rapid UI changes.\nBetter error handling: You can implement retry logic or error handling for the entire batch rather than for individual operations.\nThis pattern is particularly valuable in applications where users might trigger many small actions that would otherwise each result in an API call, such as:\nCollaborative editing tools (like Google Docs) Form interfaces where multiple fields might be changed quickly Real-time data entry applications Applications with autosave functionality Libraries like Apollo Client for GraphQL use similar batching techniques to combine multiple queries or mutations that occur within the same execution frame.\nLei: But apiClient.updateUser will be called every time we call scheduleUserUpdate. Are you assuming apiClient.updateUser needs to handle batching as well? Assistant: You\u0026rsquo;re absolutely right, and I made a mistake in my example. The way I structured it, apiClient.updateUser would indeed be called multiple times - once for each user, but not properly batching the calls themselves.\nLet me correct this with a proper implementation that actually batches API calls:\n// The original queue implementation let timeout = null; const queue = new Set(); function process() { for (const task of queue) { task(); } queue.clear(); timeout = null; } function enqueue(task) { if (timeout === null) timeout = setTimeout(process, 0); queue.add(task); } // Improved API call batching const pendingUpdates = {}; function scheduleUserUpdate(userId, fieldName, value) { // Initialize user\u0026#39;s pending updates if needed if (!pendingUpdates[userId]) { pendingUpdates[userId] = {}; } // Add this field update to the pending batch pendingUpdates[userId][fieldName] = value; // Schedule a single processing function if not already scheduled if (timeout === null) { enqueue(() =\u0026gt; { // Create a copy of all pending updates const updates = {...pendingUpdates}; // Clear the pending updates for (const userId in pendingUpdates) { delete pendingUpdates[userId]; } // Make a SINGLE API call with all batched updates apiClient.batchUpdateUsers(updates); }); } } // Usage - all these would be combined into one API call scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;John Smith\u0026#39;); scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;email\u0026#39;, \u0026#39;john@example.com\u0026#39;); scheduleUserUpdate(\u0026#39;user456\u0026#39;, \u0026#39;status\u0026#39;, \u0026#39;active\u0026#39;); In this corrected version:\nWe collect all user updates in the pendingUpdates object We schedule a single processing function that will run once in the next event loop When the processing function runs, it sends ALL pending updates in one API call This approach assumes your API has a batched endpoint like batchUpdateUsers that can handle updates to multiple users at once. If your API only supports updating one user at a time, you might still need to make multiple API calls, but you would at least consolidate all the field updates for each user.\nThank you for catching that error in my explanation!\nLei: Can you give me a more realistic example?\nIn the real world, experienced programmers know to make one API call with all the updated info, like apiClient.updateUser(allUpdates)\nNo one would write code like\nscheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;John Smith\u0026#39;); scheduleUserUpdate(\u0026#39;user123\u0026#39;, \u0026#39;email\u0026#39;, \u0026#39;john@example.com\u0026#39;); scheduleUserUpdate(\u0026#39;user456\u0026#39;, \u0026#39;status\u0026#39;, \u0026#39;active\u0026#39;); Assistant: You\u0026rsquo;re absolutely right. Let me provide a more realistic example that better reflects how experienced developers would implement API call batching.\nHere\u0026rsquo;s a real-world scenario involving a data analytics dashboard:\n// Our task queue implementation let timeout = null; const queue = new Set(); function process() { for (const task of queue) { task(); } queue.clear(); timeout = null; } function enqueue(task) { if (timeout === null) timeout = setTimeout(process, 0); queue.add(task); } // A more realistic example: Analytics event tracking class AnalyticsTracker { constructor(apiClient) { this.apiClient = apiClient; this.eventQueue = []; this.isScheduled = false; } trackEvent(eventName, eventData) { // Add to local queue this.eventQueue.push({ name: eventName, data: eventData, timestamp: Date.now() }); // Schedule batch sending if not already scheduled if (!this.isScheduled) { this.isScheduled = true; enqueue(() =\u0026gt; this.sendBatch()); } } sendBatch() { if (this.eventQueue.length === 0) { this.isScheduled = false; return; } // Get all current events const events = [...this.eventQueue]; this.eventQueue = []; this.isScheduled = false; // Send as a single batch this.apiClient.logEvents(events) .catch(error =\u0026gt; { console.error(\u0026#39;Failed to send events:\u0026#39;, error); // Re-queue failed events this.eventQueue = [...events, ...this.eventQueue]; enqueue(() =\u0026gt; this.sendBatch()); }); } } // Usage in application code const analytics = new AnalyticsTracker(apiClient); // These events will be batched together automatically document.querySelector(\u0026#39;#search-button\u0026#39;).addEventListener(\u0026#39;click\u0026#39;, () =\u0026gt; { analytics.trackEvent(\u0026#39;search\u0026#39;, { query: searchInput.value }); }); productList.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { if (e.target.matches(\u0026#39;.product-card\u0026#39;)) { analytics.trackEvent(\u0026#39;product_view\u0026#39;, { productId: e.target.dataset.productId }); } }); // When user scrolls, filtering, sorting, etc. window.addEventListener(\u0026#39;scroll\u0026#39;, throttle(() =\u0026gt; { const scrollDepth = getScrollPercentage(); analytics.trackEvent(\u0026#39;scroll_depth\u0026#39;, { depth: scrollDepth }); }, 2000)); In this more realistic example:\nEvents naturally occur throughout the application from user interactions Individual components don\u0026rsquo;t need to know about batching - they just call trackEvent() The analytics tracker automatically batches events that occur within the same execution frame It includes error handling and retry logic for failed API calls This is particularly useful for:\nAnalytics/telemetry where many events might fire rapidly (scroll, mouse movements) Real-time collaborative applications where multiple users make changes Auto-saving in document editors where changes should be buffered Applications that need to maintain offline functionality and sync later The key benefit is that application code remains clean and focused on business logic without needing to manually handle batching everywhere.\n","permalink":"https://leihuang.me/posts/learn-batching-from-llm/","summary":"\u003cp\u003eI was reviewing my old notebook and came across a piece of code that I took from somewhere many years ago. I asked Claude 3.7 Sonnet about this code, and here\u0026rsquo;s the conversation:\u003c/p\u003e\n\n\n\u003cdiv class=\"message user-message\"\u003e\n  \u003cdiv class=\"speaker-name\"\u003eLei:\u003c/div\u003e\n  \u003cdiv class=\"message-content\"\u003e\u003cp\u003eTake a look at the following code:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-javascript\" data-lang=\"javascript\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elet\u003c/span\u003e \u003cspan class=\"nx\"\u003etimeout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003equeue\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nx\"\u003eSet\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003efunction\u003c/span\u003e \u003cspan class=\"nx\"\u003eprocess\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kr\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003etask\u003c/span\u003e \u003cspan class=\"k\"\u003eof\u003c/span\u003e \u003cspan class=\"nx\"\u003equeue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nx\"\u003etask\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nx\"\u003equeue\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eclear\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nx\"\u003etimeout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003efunction\u003c/span\u003e \u003cspan class=\"nx\"\u003eenqueue\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003etask\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003etimeout\u003c/span\u003e \u003cspan class=\"o\"\u003e===\u003c/span\u003e \u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"nx\"\u003etimeout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nx\"\u003esetTimeout\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003eprocess\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nx\"\u003equeue\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003etask\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eI\u0026rsquo;m not sure how is this code useful. One scenario I can think of is modifying the DOM. Doing DOM manipulation in one batch might avoid reflow. But I\u0026rsquo;m fuzzy on details. Can you give me a concrete example?\u003c/p\u003e","title":"Learn Batching From LLM"},{"content":"Recently, I faced a daunting task: migrating all of our existing product deals to a brand new, more comprehensive, and standardized set of canonical product categories. This was critical for improving product discoverability, ensuring consistent marketing, and enabling better reporting. Think of it as moving from a somewhat disorganized, ad-hoc filing system to a meticulously organized, hierarchical library catalog.\nThe problem? Our system had tens of thousands of deals, each with existing category assignments that were often inconsistent, incomplete, or simply didn\u0026rsquo;t map cleanly to the new structure. Manually re-categorizing everything was out of the question. It would have taken an absurd amount of time and been incredibly prone to errors. I needed an automated solution, but a simple keyword-based approach wouldn\u0026rsquo;t work. The nuances of product descriptions and the potential mismatches between the old and new categories demanded something far more intelligent.\nThe Challenge: Bridging the Old and New The core challenge was bridging the semantic gap between the existing (often messy) category assignments and the new canonical categories. Here are a few examples to illustrate the problem:\nOld: \u0026ldquo;mens-clothing.shirts-t-shirts\u0026rdquo; New: \u0026ldquo;Apparel.Men\u0026rsquo;s.Tops.T-Shirts\u0026rdquo; Old: \u0026ldquo;health-beauty.fragrance-cologne\u0026rdquo; New: \u0026ldquo;Beauty \u0026amp; Personal Care.Fragrances.Men\u0026rsquo;s Fragrances\u0026rdquo; Old: \u0026ldquo;home-decor\u0026rdquo; New: \u0026ldquo;Home \u0026amp; Garden.Home Decor.Candles \u0026amp; Home Fragrances\u0026rdquo; (for a scented candle deal) The old categories could be incomplete, use different wording, or have a different level of granularity. I couldn\u0026rsquo;t just create a simple lookup table. I needed a system that could:\nUnderstand the meaning of the product description, going beyond simple keyword matching. Leverage the existing category information, even if imperfect, as a valuable hint. Intelligently select the best match within the new canonical category hierarchy. My AI-Powered Solution: A Two-Stage Migration I developed a two-stage AI-powered system that combines the strengths of embedding-based similarity matching and the contextual reasoning of large language models (LLMs).\nStage 1: Embedding-Based Similarity – Finding the Right Neighborhood The first stage leverages pre-computed embeddings of the new canonical categories. Embeddings are numerical representations that capture the semantic meaning of text. Similar concepts have similar embeddings. I calculated the embedding of each product deal\u0026rsquo;s description (including the title and any existing category information, after some complex preprocessing). Then, I compared this \u0026ldquo;deal embedding\u0026rdquo; to the embeddings of all the top-level categories in the new taxonomy.\n// (Simplified representation) import { calculateCosineSimilarity } from \u0026#34;./similarity\u0026#34;; import canonicalCategoryData from \u0026#34;./canonical_categories.json\u0026#34;; // My NEW category embeddings import { getAIClient } from \u0026#34;./ai_client\u0026#34;; // Interface to AI models async function migrateCategory(dealDetails) { const { title, description, existingCategories } = dealDetails; const { createTextEmbedding } = getAIClient(); // 1. Create an embedding for the deal, including (preprocessed) existing categories. const dealEmbedding = await createTextEmbedding( `${title} ${description} ${ existingCategories ? prepareCategories(existingCategories) : \u0026#34;\u0026#34; }` ); // 2. Compare against top-level canonical category embeddings. const topLevelCategories = Object.entries(canonicalCategoryData).map( ([key, data]) =\u0026gt; [key, data.embedding] ); let bestMatch = null; let highestScore = -Infinity; for (const [categoryName, categoryEmbedding] of topLevelCategories) { const similarity = calculateCosineSimilarity( dealEmbedding, categoryEmbedding ); if (similarity \u0026gt; highestScore) { highestScore = similarity; bestMatch = categoryName; } } // ... (continued below) } I used cosine similarity to measure how \u0026ldquo;close\u0026rdquo; the embeddings are. A score of 1 is a perfect match; -1 is completely opposite. This quickly and efficiently identifies the general area within the new category structure where the deal likely belongs. If the similarity score exceeds a threshold (I used 0.8), I\u0026rsquo;m confident enough to assign the deal to that top-level category. Then, I repeat the process with the sub-categories of that top-level to get a more precise placement (e.g., \u0026ldquo;Apparel\u0026rdquo; -\u0026gt; \u0026ldquo;Men\u0026rsquo;s\u0026rdquo; -\u0026gt; \u0026ldquo;Tops\u0026rdquo; -\u0026gt; \u0026ldquo;T-Shirts\u0026rdquo;).\nStage 2: LLM Reasoning – Refining the Choice What if the embedding similarity is below my threshold? This is where the LLM comes in, handling cases where:\nThe deal description is brief or uses unusual language. The existing categories are particularly unhelpful or misleading. The best fit in the new taxonomy isn\u0026rsquo;t immediately obvious. I construct a prompt for the LLM that includes:\nThe deal\u0026rsquo;s title and description. The (potentially cleaned-up) existing categories. A list of the new canonical categories to choose from. // (Continuing from the previous code snippet) const SIMILARITY_THRESHOLD = 0.8; async function migrateCategory(dealDetails) { // ... (previous code) // If similarity is high enough, we\u0026#39;re done! if (highestScore \u0026gt;= SIMILARITY_THRESHOLD) { const subCategories = canonicalCategoryData[bestMatch].children; // Get sub-categories const subCategoryMatch = await findBestSubCategory( dealEmbedding, subCategories ); // Find the best sub-category return [bestMatch, subCategoryMatch].filter(Boolean).join(\u0026#34;.\u0026#34;); // Return \u0026#34;TopLevel.SubLevel\u0026#34; } // If similarity is low, bring in the LLM. const availableCategories = topLevelCategories.map( ([categoryName]) =\u0026gt; categoryName ); const suggestedCategory = await getCategorySuggestion( dealDetails, availableCategories ); return suggestedCategory; } The getCategorySuggestion function (shown later) interacts with the LLM, providing the prompt and receiving the suggested category. The LLM acts like a \u0026ldquo;smart categorizer,\u0026rdquo; using its contextual understanding to make the best decision.\nThe Key: Cleaning Up the Existing Categories The most crucial and, I think, trickiest part of my solution is how I handle the existing category information. I can\u0026rsquo;t just ignore it; it often contains valuable clues. But I can\u0026rsquo;t trust it blindly, either. The refineExistingCategories function is the key to this delicate balance.\nexport function refineExistingCategories( categories: string, similarityScores: number[] ): string { const keywords = categories .split(\u0026#34;,\u0026#34;) .map((cat) =\u0026gt; cat.split(\u0026#34;.\u0026#34;).map((subCat) =\u0026gt; subCat.split(\u0026#34;-\u0026#34;))); let i = 0; function filterKeywords(arr: any[]): any[] { return arr .map((item) =\u0026gt; { if (Array.isArray(item)) { return filterKeywords(item); } // THIS IS THE CORE LOGIC: Remove keywords with low similarity. return similarityScores[i++] \u0026gt; KEYWORD_SIMILARITY_THRESHOLD ? item : null; }) .filter((item) =\u0026gt; item !== null); } return (filterKeywords(keywords) as string[][][]) .map((category) =\u0026gt; category .map((subCategory) =\u0026gt; { return subCategory.join(\u0026#34;-\u0026#34;); }) .join(\u0026#34;.\u0026#34;) ) .join(\u0026#34;,\u0026#34;); } Here\u0026rsquo;s a breakdown:\nDeconstruct: I break down the existing categories into a hierarchical structure of individual keywords. For example, \u0026ldquo;health-beauty.fragrance-cologne,mens-clothing\u0026rdquo; becomes [[[\u0026quot;health\u0026quot;, \u0026quot;beauty\u0026quot;], [\u0026quot;fragrance\u0026quot;, \u0026quot;cologne\u0026quot;]], [[\u0026quot;mens\u0026quot;, \u0026quot;clothing\u0026quot;]]].\nIndividual Keyword Embeddings: I create an embedding for each individual keyword from the old categories.\nSimilarity Check: I compare each keyword embedding to the embedding of the deal description ( without the old categories). This measures how relevant each individual keyword is to the core product information.\nStrategic Removal: If a keyword\u0026rsquo;s similarity is below a threshold (KEYWORD_SIMILARITY_THRESHOLD, which I set to 0.75), I remove it. This eliminates noise and prevents misleading information from influencing the LLM.\nReconstruct: I rebuild the \u0026ldquo;cleaned\u0026rdquo; existing categories string using only the remaining keywords.\nExample:\nLet\u0026rsquo;s say a deal for a men\u0026rsquo;s cologne has the old category \u0026ldquo;health-beauty.fragrance-cologne\u0026rdquo;.\nKeywords: [[[\u0026quot;health\u0026quot;, \u0026quot;beauty\u0026quot;], [\u0026quot;fragrance\u0026quot;, \u0026quot;cologne\u0026quot;]]] Embeddings: I create embeddings for \u0026ldquo;health\u0026rdquo;, \u0026ldquo;beauty\u0026rdquo;, \u0026ldquo;fragrance\u0026rdquo;, and \u0026ldquo;cologne\u0026rdquo;. Similarity: I compare each to the deal description embedding. \u0026ldquo;health\u0026rdquo; and \u0026ldquo;beauty\u0026rdquo; likely have low similarity; \u0026ldquo;fragrance\u0026rdquo; and \u0026ldquo;cologne\u0026rdquo; have high similarity. Removal: \u0026ldquo;health\u0026rdquo; and \u0026ldquo;beauty\u0026rdquo; are removed. Result: The cleaned category becomes \u0026ldquo;fragrance-cologne\u0026rdquo;. This \u0026ldquo;cleaned\u0026rdquo; category is then used in the LLM prompt, providing a much more focused and relevant hint. This significantly boosts the accuracy of the LLM\u0026rsquo;s suggestions.\nThe Full Code Here\u0026rsquo;s a more complete view of the code, including helper functions and the LLM interaction:\nimport { calculateCosineSimilarity } from \u0026#34;./similarity\u0026#34;; import canonicalCategoryData from \u0026#34;./canonical_categories.json\u0026#34;; import { getAIClient } from \u0026#34;./ai_client\u0026#34;; type CategoryData = typeof canonicalCategoryData; const SIMILARITY_THRESHOLD = 0.8; const KEYWORD_SIMILARITY_THRESHOLD = 0.75; async function findBestMatch\u0026lt;T extends string\u0026gt;({ title, description, existingCategories, sourceEmbedding, comparisonEmbeddings, }: { title: string; description: string; existingCategories?: string | null; sourceEmbedding: Array\u0026lt;number\u0026gt; | null; comparisonEmbeddings: Array\u0026lt;[T, Array\u0026lt;number\u0026gt;]\u0026gt;; }): Promise\u0026lt;T | undefined\u0026gt; { let bestMatch: string | null = null; let highestScore = -Infinity; const { createTextEmbedding } = getAIClient(); if (sourceEmbedding !== null) { // Calculate cosine similarities and find the best match (embedding stage). comparisonEmbeddings.forEach(([targetCategory, targetEmbedding]) =\u0026gt; { const similarity = calculateCosineSimilarity( sourceEmbedding, targetEmbedding ); if (similarity \u0026gt; highestScore) { highestScore = similarity; bestMatch = targetCategory; } }); } if (highestScore \u0026gt;= SIMILARITY_THRESHOLD) return bestMatch as T; // LLM Fallback (if embedding similarity is low) const targetCategoryNames = comparisonEmbeddings.map( ([category]) =\u0026gt; category ); // No existing categories? Simple LLM prompt. if (!existingCategories) { return await getCategorySuggestion\u0026lt;T\u0026gt;( `Product title: ${title}\\nProduct description: ${description}\\nAvailable categories:\\n`, targetCategoryNames ); } // Existing categories? Refine them *first* const categoryKeywords = existingCategories.split(/[^a-zA-Z0-9]/g); const keywordEmbeddings = await Promise.all( categoryKeywords.map((keyword) =\u0026gt; createTextEmbedding(keyword)) ); const productEmbeddingWithoutCategories = await createTextEmbedding( `${title} ${description}` ); if ( keywordEmbeddings.every((e) =\u0026gt; e !== null) \u0026amp;\u0026amp; productEmbeddingWithoutCategories ) { const similarities = (keywordEmbeddings as unknown as number[][]).map( (embedding) =\u0026gt; calculateCosineSimilarity(embedding, productEmbeddingWithoutCategories) ); const refinedCategories = refineExistingCategories( existingCategories, similarities ); const prompt = `Product title: ${title}\\nProduct description: ${description}\\nPrevious categories: ${refinedCategories}\\nAvailable categories:\\n`; return await getCategorySuggestion\u0026lt;T\u0026gt;(prompt, targetCategoryNames); } } async function getCategorySuggestion\u0026lt;T extends string\u0026gt;( partialPrompt: string, availableCategories: T[] ): Promise\u0026lt;T | undefined\u0026gt; { const { createChatCompletion } = getAIClient(); const suggestion = await createChatCompletion({ systemMessage: \u0026#34;You are a categorization assistant that helps choose new product categories during a taxonomy migration.\u0026#34;, userMessage: `${partialPrompt}${availableCategories.join( \u0026#34;, \u0026#34; )}\\nNew category:`, }); if (!suggestion) { return undefined; } // Ensure the suggestion is one of the available categories. return availableCategories.find( (c) =\u0026gt; c.toLowerCase() === suggestion.trim().toLowerCase() ); } export function prepareCategories(categories: string) { return [...new Set(categories.split(/[^a-zA-Z0-9]/g))].join(\u0026#34; \u0026#34;); } export async function migrateCategory(dealDetails: { title: string; description: string; existingCategories?: string | null; }) { const { createTextEmbedding } = getAIClient(); const { title, description, existingCategories } = dealDetails; const dealEmbedding = await createTextEmbedding( `${title} ${description}${ existingCategories ? ` ${prepareCategories(existingCategories)}` : \u0026#34;\u0026#34; }` ); const topLevelCategories = Object.entries(canonicalCategoryData).map\u0026lt; [keyof CategoryData, number[]] \u0026gt;(([key, data]) =\u0026gt; [key, data.embedding]); const topLevelMatch = await findBestMatch\u0026lt;keyof CategoryData\u0026gt;({ sourceEmbedding: dealEmbedding, comparisonEmbeddings: topLevelCategories, title, description, existingCategories, }); if (!topLevelMatch) { return null; } const subLevelMatch = await findBestMatch\u0026lt;string\u0026gt;({ title, description, existingCategories, sourceEmbedding: dealEmbedding, comparisonEmbeddings: canonicalCategoryData[topLevelMatch].children as [ string, number[] ][], }); return [topLevelMatch, subLevelMatch].filter(Boolean).join(\u0026#34;.\u0026#34;); } Key Results and Benefits I\u0026rsquo;m quite proud of what I achieved with this migration system. It allowed me to:\nDramatically improve accuracy: The combination of embeddings and LLMs significantly outperformed any manual or rule-based approach I could have devised. Save enormous amounts of time: What would have taken weeks or months of manual effort was completed in a fraction of the time. Ensure consistency: The automated system applied the new taxonomy consistently across all deals. Handle complexity: The system gracefully handled variations in product descriptions and ambiguities in the existing categories. Be adaptable: I can easily fine-tune the system (e.g., adjust the similarity thresholds) or update it as the canonical category structure evolves. This task is an example of how AI can be used to tackle complex, real-world data challenges. By combining different AI techniques and focusing on the nuances of the problem, I was able to build a solution that was both powerful and practical. The key was understanding the strengths of each approach – embeddings for efficient similarity matching, LLMs for contextual understanding, and careful preprocessing to clean up noisy data – and combining them in a resilient way.\n","permalink":"https://leihuang.me/posts/category-mapping-with-embedding/","summary":"\u003cp\u003eRecently, I faced a daunting task: migrating all of our existing product deals to a brand new, more comprehensive, and standardized set of canonical product categories. This was critical for improving product discoverability, ensuring consistent marketing, and enabling better reporting. Think of it as moving from a somewhat disorganized, ad-hoc filing system to a meticulously organized, hierarchical library catalog.\u003c/p\u003e\n\u003cp\u003eThe problem? Our system had \u003cem\u003etens of thousands\u003c/em\u003e of deals, each with existing category assignments that were often inconsistent, incomplete, or simply didn\u0026rsquo;t map cleanly to the new structure. Manually re-categorizing everything was out of the question. It would have taken an absurd amount of time and been incredibly prone to errors. I needed an automated solution, but a simple keyword-based approach wouldn\u0026rsquo;t work. The nuances of product descriptions and the potential mismatches between the old and new categories demanded something far more intelligent.\u003c/p\u003e","title":"Category Mapping with Embedding"},{"content":"I wrote about time-slicing with CPS technique in the last blog post. The solution I proposed has two drawbacks:\nThe control over task scheduling is too weak. Task slicing relies entirely on hacking the JavaScript engine\u0026rsquo;s event loop, and it\u0026rsquo;s impossible to arbitrarily pause and resume. This makes it impossible to precisely time the slices; you can only set them based on subjective experience (the example I provided uses 500 as the interval). However, 500 tasks might still be too long, causing the main thread to be blocked for too long. Or it might be too short, not fully utilizing the current call stack. setTimeout\u0026rsquo;s timing is inaccurate, and the actual time interval will have deviations. The result is that the delays of each task accumulate, significantly increasing the total task completion time. An alternative solution: Coroutine If a computational task can suspend itself and yield execution to other tasks, it\u0026rsquo;s a coroutine.\nIn JavaScript, we can arbitrarily pause and resume a program with Generators.\nFirst, we implement a coroutine scheduler, which isn\u0026rsquo;t very complex:\nfunction run(coroutine, threshold = 1, options = { timeout: 160 }) { return new Promise(function (resolve, reject) { const iterator = coroutine() window.requestIdleCallback(step, options) function step(deadline) { const minTime = Math.max(0.5, threshold) try { while (deadline.timeRemaining() \u0026gt; minTime) { const { value, done } = iterator.next() if (done) { resolve(value) return } } } catch (e) { reject(e) return } // If we reach here, it means the task timed out. Place the remaining task in the next idle period. window.requestIdleCallback(step, options) } }) } The run scheduler uses requestIdleCallback to get the browser\u0026rsquo;s remaining time budget. Within this time budget, the scheduler iteratively executes the passed-in coroutine (iterator.next()). If the task completes, the loop terminates, and the Promise resolves. If it times out, the remaining task is placed in the next idle period via requestIdleCallback.\nThe indexNews task we were dealing with was essentially a list fold operation. We can implement a coroutine version of reduce to help us accomplish the same task we did with for loop.\nfunction* reduce(array, fn, initial) { let result = initial || array[0] for (let i = 0; i \u0026lt; array.length; i++) { result = yield* fn(result, array[i], i, array) } return result } function sliceTask(fn, yieldInterval = 10) { let yieldCount = 0 return function* sliced(...params) { let result = fn(...params) if (yieldCount++ \u0026gt; yieldInterval) { yieldCount = 0 yield } return result } } function reduceAsync(array, reducer, initial) { return run(compute) function* compute() { return yield* reduce(array, sliceTask(reducer, 20), initial) } } const indexedData = await reduceAsync( newsList, (newsMap, item) =\u0026gt; { for (const tag of item.tags) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]) } else { newsMap.get(tag).push(item) } } }, new Map() ) The purpose of sliceTask is to convert ordinary tasks into coroutines. After the task has been executed a certain number of times (default is 10), it yields, giving the outer driver a chance to check timeRemaining() and decide whether to interrupt.\nThe coroutine scheduling method described above is not limited to the browser. By simulating requestIdleCallback in Node.js (similar to React\u0026rsquo;s scheduler, which is straightforward to implement), this technique can also be used for task scheduling on the server-side.\n","permalink":"https://leihuang.me/posts/time-slicing-with-coroutine/","summary":"\u003cp\u003eI wrote about \u003ca href=\"/posts/time-slicing-with-cps/\"\u003etime-slicing with CPS technique\u003c/a\u003e in the last blog post. The solution I proposed has two drawbacks:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe control over task scheduling is too weak. Task slicing relies entirely on hacking the JavaScript engine\u0026rsquo;s event loop, and it\u0026rsquo;s impossible to arbitrarily pause and resume. This makes it impossible to precisely time the slices; you can only set them based on subjective experience (the example I provided uses 500 as the interval). However, 500 tasks might still be too long, causing the main thread to be blocked for too long. Or it might be too short, not fully utilizing the current call stack.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esetTimeout\u003c/code\u003e\u0026rsquo;s timing is inaccurate, and the actual time interval will have deviations. The result is that the delays of each task accumulate, significantly increasing the total task completion time.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"an-alternative-solution-coroutine\"\u003eAn alternative solution: Coroutine\u003c/h2\u003e\n\u003cp\u003eIf a computational task can suspend itself and yield execution to other tasks, it\u0026rsquo;s a coroutine.\u003c/p\u003e","title":"Time-slicing With Coroutine"},{"content":"Background story In January this year, I applied for an overseas dev job. I was asked to finish a project as homework. The project required a ton of computations on the front end, which posed a challenge as I must ensure no operations should block the main thread. I didn\u0026rsquo;t want to move the computation to a worker thread because the data was consumed in the main thread. Serializing and de-serializing a large set of data also has a performance cost. Furthermore, to improve indexing performance, I used Map to store the results, which is not serializable.\nThe task involved is as following:\nProcess a long list of news items, and index each item according to its tags. It looks like this in code:\nconst newsList = [ { uid: \u0026#34;8be34939-bc25-4b9e-999d-2daf19fbea7b\u0026#34;, title: \u0026#34;Adipisicing do eu magna ex non est eu labore nisi duis enim elit.\u0026#34;, tags: [\u0026#34;reprehenderit\u0026#34;, \u0026#34;cupidatat\u0026#34;, \u0026#34;ad\u0026#34;, \u0026#34;ea\u0026#34;, \u0026#34;labore\u0026#34;], }, { uid: \u0026#34;488399fc-e474-4c52-a36c-625e2218fabe\u0026#34;, title: \u0026#34;Elit aute tempor dolore do sunt.\u0026#34;, tags: [\u0026#34;sint\u0026#34;, \u0026#34;ea\u0026#34;, \u0026#34;Lorem\u0026#34;, \u0026#34;consectetur\u0026#34;, \u0026#34;officia\u0026#34;], }, { uid: \u0026#34;0340b317-bd55-4c43-9982-94bf9d08b977\u0026#34;, title: \u0026#34;Aliquip qui est sint veniam consectetur.\u0026#34;, tags: [\u0026#34;sit\u0026#34;, \u0026#34;ullamco\u0026#34;, \u0026#34;consectetur\u0026#34;], }, // ... omit remaining tens of thousands of items ]; const newsMap = new Map(); newsList.forEach((news) =\u0026gt; { news.tags.forEach((tag) =\u0026gt; { if (!newsMap.has(tag)) { newsMap.set(tag, [news]); } else { newsMap.get(tag).push(news); } }); }); In practice, I\u0026rsquo;d never done massive computations on the front-end, as JavaScript is not very efficient in handling CPU-intensive work. However, after some google search, I found a way to get around this limitation. The idea is to slice a big task to many small ones and put them to different callstacks.\nTime-slicing to the rescue If you\u0026rsquo;ve been working with React long enough, you\u0026rsquo;ve probably heard of React Fiber and time-slicing. React Fiber is a new reconciliation algorithm inside of the React core. It was designed to enable React to handle computations(mostly diffing caused by setState) in a non-blocking way. When high priority tasks occur due to user inputs, React can pause low priority tasks and handle them immediately.\nThe fiber architecture is very complicated. The implementation of it is quite cryptic and daunting. Implementing a fiber algorithm in my little project would be an overkill, if not infeasible. However, I can still do time-slicing in JavaScript in an easier way.\nThe solution lies in JavaScript\u0026rsquo;s power in asynchronicity and callback functions. Encountered with asynchronous tasks, we tend to shun away from callbacks because of the dreaded \u0026ldquo;callback hell.\u0026rdquo; However, when handled properly, callbacks and asynchronicity are a good fit. The callback soup I\u0026rsquo;m about to introduce is very powerful and irreplaceable.\nIf you used to pass callbacks in Ajax programming or node.js event handlers, you already know the technique I\u0026rsquo;m going to show you. I just find a fancier name for it: CPS(Continuation-passing Style).\nWhat is CPS Here\u0026rsquo;s an identity function you would write normally:\nfunction id(x) { return x; } and here is a CPS version:\nfunction id(x, cb) { cb(x); } In continuation-passing style, instead of \u0026ldquo;returning\u0026rdquo; the procedure to its caller, you invoke the \u0026ldquo;current continuation\u0026rdquo; callback (provided by the caller) on the return value.\nThe foundation of CPS is simple:\nProcedures can take a callback to invoke upon their return value. Slice it up! The atomic operation we need to do in processing the list is as following:\nfunction indexNews(item, tag) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } } So we need to slice our previous one big task to many small tasks like the above one. Here\u0026rsquo;s how to do it:\nfunction indexNews(item, tag, continuation) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } continuation(); } function iterate(list, processTask, continuation) { function handleOne(i, j, _continuation) { if (i \u0026lt; list.length) { const item = list[i]; if (j \u0026lt; item.tags.length) { processTask(item, item.tags[j], function handleNext() { handleOne(i, j + 1, _continuation); }); } else { handleOne(i + 1, 0, _continuation); } } else { _continuation(); } } handleOne(0, 0, continuation); } iterate(newsList, indexNews, () =\u0026gt; { // Indexing is done, // we can enable features that depend on indexing safely here. console.log(\u0026#34;done\u0026#34;); }); This introduces too many recursions and makes our code way more complicated without improving performance. But we are very close!\nNotice a very important feature of the indexNews function. It takes a continuation callback and calls the continuation after finishing the current task. We\u0026rsquo;ve achieved \u0026ldquo;Inversion of Control\u0026rdquo; here. We can tell indexNews what to do in the next iteration.\nIn our case, we want it to move subsequent tasks to a new callstack so that we don\u0026rsquo;t put too much pressure on the current callstack.\nHowever, we don\u0026rsquo;t want to move every task to its own callstack, which is unnecessary.\nSo, here\u0026rsquo;s the rule:\nEach callstack can take 500 tasks, after that limit, we put the next 500 tasks in the next callstack. Repeat until all tasks are done.\nWe just need a few modifications to our previous code to achieve this:\nfunction indexNews(item, tag, continuation) { if (!newsMap.has(tag)) { newsMap.set(tag, [item]); } else { newsMap.get(tag).push(item); } if (indexNews.skip++ % 500 === 0) { setTimeout(continuation, 0); } else { continuation(); } } indexNews.skip = 0; Because of how event loop works in JavaScript, the setTimeout method will move its callback to the next execution callstack.\nSummary We introduced a technique we already knew and rediscovered the hidden power of it. Continuation-passing Style enables us to have control over what happens next when the current operation is completed. Relying on this feature, we first sliced a very big task to many small ones, and then chunked them into different call stacks.\nCheck out the project here .\n","permalink":"https://leihuang.me/posts/time-slicing-with-cps/","summary":"\u003ch2 id=\"background-story\"\u003eBackground story\u003c/h2\u003e\n\u003cp\u003eIn January this year, I applied for an overseas dev job. I was asked to finish a\nproject as homework. The project required a ton of computations on the front\nend, which posed a challenge as I must ensure no operations should block the\nmain thread. I didn\u0026rsquo;t want to move the computation to a worker thread because\nthe data was consumed in the main thread. Serializing and de-serializing a large\nset of data also has a performance cost. Furthermore, to improve indexing\nperformance, I used \u003ccode\u003eMap\u003c/code\u003e to store the results, which is not serializable.\u003c/p\u003e","title":"Time-slicing With Continuation-passing Style"},{"content":"Background I recently rewrote my blog website from scratch in Gatsby. This time, I didn’t use a starter template, so I had to make a lot of design decisions. When I wrote the bio section on the home page, initially I put a long heading there as a one-sentence introduction. As I was gazing at the screen, I felt something was wrong. It was too wordy. But after I took out a few words, I was not satisfied with what was left.\nAfter some trying, I came up with an idea. Why not add a typewriter to present more contents with less space? It also adds a lot of fun and dynamic to the page. It seems like legit reasoning, so I did it. I was satisfied at this time.\nA typewriter effect requires dealing with asynchronicity. I can do it in vanilla JavaScript, but the result code would be very complex, with a lot of timer events scattering around. When dealing with complex asynchronous event handling, my rule of thumb is to use tools that help me focus on the desired effects, rather than the housekeeping juggling work. RxJS stands out as my tool of choice for this role.\nWhy RxJS? RxJS enables you to encode time in values. As I see it, the greatest power of RxJS is that it enables you to encode time in values. Time becomes tangible and can be mixed and matched with other values. In the movie Arrival, an alien language can encode time in itself, so the speaker of that language is capable of foreseeing the future. RxJS is similar in a sense. When programming, you’re the dictator of all events, you already knew what will happen before you start. In RxJS, or reactive programming in a broader sense, you can encode future events in a placeholder (I try to avoid \u0026lsquo;variable\u0026rsquo; because it may be confusing for beginners) as you declare it.\nThink about the typewriter effect. What we really want is to display different texts on the screen over time. For instance, if we want to type ‘hello’ and then delete it, we want the texts delivered to us over time like this:\n// type h---he---hel---hell---hello // pause -------- // delete hello---hell---hel---he---h // pause -------- We can tell RxJS, “Hey, this is the word, I want you to slice it up like this and give the pieces back to me over time.”\nEncode time in values After we have a clear vision of what we want, let’s do it and write the code!\nStart with the basics. We need to type a single word first. It’s easy.\nconst type = ({word, speed}) =\u0026gt; interval(speed).pipe( map(x =\u0026gt; word.substr(0, x + 1)), take(word.length) ) The interval source will fire up events as per the speed value we provide in milliseconds. Each time it will emit a number increasingly. When the event occurs, we map the emitted value to characters from the word. The interval timer will fire indefinitely, but we only take what we want. After passing the limit specified by the take operator, the timer will stop.\nWe also need a delete effect. Let’s add a parameter ‘backward’ to the type function. We slice differently when ‘backward’ is specified.\nconst type = ({word, speed, backward = false}) =\u0026gt; interval(speed).pipe( map(x =\u0026gt; backward ? word.substr(0, word.length - x - 1) : word.substr(0, x + 1) ), take(word.length) ) To combine the type-pause-delete-pause effects together, we need the concat operator to concatenate 4 event sources (we\u0026rsquo;ll call them observables from now on)\nconst typeEffect = word =\u0026gt; concat( type({word, speed: 70}), // type of(\u0026#39;\u0026#39;).pipe(delay(1500), ignoreElements()), // pause type({word, speed: 30, backward: true}), // delete of(\u0026#39;\u0026#39;).pipe(delay(300), ignoreElements()) // pause ) We type and delete at different speeds. And also pause differently after typing and deleting. For pausing effect, we emit an empty string and delay the event. ignoreElements operator just ignore emmited values. This is to only encode time itself and discard any values.\nThen we move on to type multiple words. Using the from operator, we can turn an array into an observable, which is a term to describe \u0026ldquo;values over time\u0026rdquo;. After this, we know RxJS will feed us the items in the array over time. But how frequently? In what form? We’ll tell RxJS in the pursuing operators.\nconst value = useObservable(() =\u0026gt; from(words).pipe(concatMap(typeEffect), repeat()) ) useObservable is a helper function to turn values emitted from observables into React state.\nwe use concatMap to map every word into a new observable and concatenate them. Say we feed RxJS value [‘hello’, ‘how are you’, ‘bye’ ], in a diagram, it will look like this:\n----typeEffect(‘hello’) ----typeEffect(‘how are you’)---typeEffect(‘bye’)--- The repeat operator tells RxJS to repeat the source observable forever.\nThat\u0026rsquo;s all the code you need to build a typewriter effect!\nHere is a fun demo:\n","permalink":"https://leihuang.me/posts/typewritter-in-rxjs/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently rewrote my blog website from scratch in Gatsby. This time, I didn’t\nuse a starter template, so I had to make a lot of design decisions. When I wrote\nthe bio section on the home page, initially I put a long heading there as a\none-sentence introduction. As I was gazing at the screen, I felt something was\nwrong. It was too wordy. But after I took out a few words, I was not satisfied\nwith what was left.\u003c/p\u003e","title":"Typewriter Effect With RxJS"},{"content":"Recently, I encountered a situation where I need to perform text searches in a large set of data. Normally, I would do it in a filter function, but that would be slow when the list is too long. There\u0026rsquo;s a data structure for this situation. Meet the Trie!\nTrie (pronounced try) is a tree-like data structure that\u0026rsquo;s created for efficient text searches.\nHow does it work Trie takes all words and rearranges them in a tree hierarchy. For example, the list of words ['abet', 'abode', 'abort'] will be transformed into a structure like this:\n--------------- a | b / \\ e o | / \\ t d r | | e t After that, if we want to search for a word beginning with \u0026lsquo;abo\u0026rsquo;, we can skip the branch under e in the third level.\nIn this post, I\u0026rsquo;m going to walk you through the details of implementing a Trie. There\u0026rsquo;ll be a lot of code. It may be intimidating and boring as hell, but I\u0026rsquo;ll add comments at each key step.\nImplementing a Trie in JavaScript 1. Node information class TrieNode { constructor(char) { this.char = char // to store the current character this.validWord = false // if the current character is at the end of a whole word this.parent = null // parent of the current node this.children = [] // children nodes } } 2. Adding a word to a Trie First, we need a method to add a new word into a Trie:\nclass Trie { constructor() { this.root = new TrieNode(\u0026#39;\u0026#39;) } add(word) { let current = this.root // The searching pointer starts at the root. for (let i = 0; i \u0026lt; word.length; i += 1) { const ch = word[i] let found = false // Iterating through the children nodes of the current node for (let j = current.children.length; j--; ) { const child = current.children[j] if (child.char === ch) { found = true // If we find a matching character, move the pointer to the matching child current = child break } } // If we can\u0026#39;t find the character in the child node list, create a new node, and add it into the list if (!found) { current.children.push(new TrieNode(ch)) const newNode = current.children[current.children.length - 1] newNode.parent = current // Move the pointer to the newly created node current = newNode } } // After the above operations, the pointer should be at the end of a word current.validWord = true } } 3. Deleting a word from a Trie We also need a method to remove a word from a Trie.\ndelete(word) { let current = this.root; for (let i = 0; i \u0026lt; word.length; i += 1) { const ch = word[i]; let found = false; for (let j = current.children.length; j--; ) { const child = current.children[j]; if (child.char === ch) { found = true; current = child; break; } } if (!found) { // If a character of a word can\u0026#39;t be found in the children list, then we know the word is not in the Trie return; } } // After the for loop, the pointer should be at the end of the word to be deleted current.validWord = false; let stop = false; while (!stop) { if ( current.children.length === 0 \u0026amp;\u0026amp; !current.validWord \u0026amp;\u0026amp; current.parent ) { // Operate on the parent nodes at every level upwards const { parent } = current; const childIndex = parent.children.indexOf(current); const end = parent.children.length - 1; // Swap the position of the current node and the node at the end of the list. [parent.children[childIndex], parent.children[end]] = [ parent.children[end], parent.children[childIndex] ]; // Now, the node to be deleted should be at the end of the list, we just need to pop it out parent.children.pop(); // Move the pointer upwards current = parent; } else { stop = true; } } } 4. Searching for a word Before I tried to implement Trie, I\u0026rsquo;d read a lot of tutorials on this topic. Almost none of these tutorials implements full search functionality. For example, this tutorial on GeeksForGeeks implements a search method that only checks if a word is in a Trie.\nWhen we search for a word, we need to know all the related words as we type in. Here\u0026rsquo;s how to achieve this:\nsearch(input) { // inputMirror is not required. I just want the output to match the input exactly. // Otherwise, if you input Fa, the returned text would be fa const inputMirror = []; let current = this.root; for (let i = 0; i \u0026lt; input.length; i += 1) { const ch = input.charAt(i); let found = false; for (let j = current.children.length; j--;) { const child = current.children[j]; if (child.char.toLowerCase() === ch.toLowerCase()) { found = true; current = child; inputMirror.push(child.char); break; } } if (!found) { return []; } } // After the above operations, the pointer should be at the node corresponding // to the last input character const match = []; // to store all matching words const tracker = []; // keep track of found character nodes function traverse(node) { tracker.push(node.char); if (node.validWord) { const temp = inputMirror.slice(0, input.length - 1); temp.push(...tracker); match.push(temp.join(\u0026#39;\u0026#39;)); } // Recursively call all children nodes node.children.forEach(traverse); // The function that comes last to the recursion stack will be the first to execute the following command. //Since we are at the end of a Trie, we start to empty the tracker at every level upwards. // For example, when you type in fa, after matching the word \u0026#39;fabric\u0026#39;, // the tracker will contain [\u0026#39;b\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;k\u0026#39;]. // Starting from \u0026#39;k\u0026#39;, we pop out every character upwards, so that when we start to match the word \u0026#39;face\u0026#39;, the tracker is empty. tracker.pop(); } traverse(current); return match; } Limitations The implementation I just showed you is not optimal. To make it efficient, we still need to do a lot of work. For example, we can store the characters in a Binary Search Tree, so that we can search them more efficiently.\nIdeally, the time complexity of a Trie search would be M * log N, where log N is the time complexity of a binary search, M is the length of the input string.\nAnother limitation of a Trie is that building a Trie consumes a lot of memory since a Trie needs to maintain a lot of reference between nodes. If the task at hand is memory sensitive, we can use Ternary Search Tree to do a better job.\nCheck out the complete code here\n","permalink":"https://leihuang.me/posts/implementing-tri/","summary":"\u003cp\u003eRecently, I encountered a situation where I need to perform text searches in a\nlarge set of data. Normally, I would do it in a \u003ccode\u003efilter\u003c/code\u003e function, but that\nwould be slow when the list is too long. There\u0026rsquo;s a data structure for this\nsituation. Meet the Trie!\u003c/p\u003e\n\u003cp\u003eTrie (pronounced try) is a tree-like data structure that\u0026rsquo;s created for efficient\ntext searches.\u003c/p\u003e\n\u003ch2 id=\"how-does-it-work\"\u003eHow does it work\u003c/h2\u003e\n\u003cp\u003eTrie takes all words and rearranges them in a tree hierarchy. For example, the\nlist of words \u003ccode\u003e['abet', 'abode', 'abort']\u003c/code\u003e will be transformed into a structure\nlike this:\u003c/p\u003e","title":"Implementing A Trie In JavaScript"},{"content":"When I was reading Eric Elliott's article on Lenses , I was curious about how such beautiful magic can be fully implemented in JavaScript. It was a tough exploration. Many of the tutorials online are about Haskell, which cannot be easily translated to JavaScript. I read the source code of Ramda and finally grokked how it works.\nIn order to understand lenses, you need to first understand some prerequisite functional programming concepts. I’ll walk you through the essential ones.\nCurrying Currying is a technique that you use to delay function execution. It enables you to feed a function one argument at a time. For example, with function const add = (x, y) =\u0026gt; x + y, you need to feed the function two numbers at once in order to perform the calculation. What if we only have the first argument value available and want to store it in the add function context, and later call it when we’re ready? Like this:\nconst add = (x, y) =\u0026gt; x + y; // we get a value v from somewhere, and we want to store it in the add function context const addV = add(v); // and later we get a value w, we can finally perform the addition addV(w); The example is trivial, but you get the idea. Why do we want to store a value inside the context of a function? This is how we combine value with behaviors in functional programming. You’ll see what I mean once we get to the lens part.\nHere’s how we implement currying in JavaScript:\nconst curry = (fn) =\u0026gt; (...args) =\u0026gt; args.length \u0026gt;= fn.length ? fn(...args) : curry(fn.bind(undefined, ...args)); Functors Functors are just data types that you can map over. Think about JavaScript array, you can map over an array and transform the values inside of it. Functors are similar, they are ‘boxes’ that hold computational context. Let’s see a few examples:\nconst Box = (x) =\u0026gt; ({ value: x, map: (f) =\u0026gt; Box(f(x)), }); Box is a functor. We can’t see what use it has yet. But let’s observe some properties of it.\nWhen you call Box with a value, the value is stored in a context, which is the returned object. After that, you can transform the value by mapping over the context however you want.\nBox(2) .map((x) =\u0026gt; x + 1) .map((x) =\u0026gt; x * 2); We are stacking up computations by mapping. That’s all we need to know about functors for now.\nImplementing lenses Let’s put what we just learned into use and implement lenses!\nFirst, we define functional getters and setters. They’re pretty simple.\nconst prop = curry((k, obj) =\u0026gt; (obj ? obj[k] : undefined)); const assoc = curry((k, v, obj) =\u0026gt; ({ ...obj, [k]: v })); const obj = {a: 1, b: 2}; prop(‘a’)(obj) // 1 assoc(a)(3)(obj) // {a: 3, b: 2} Then we define a function to make lenses:\nconst makLens = curry( (getter, setter) =\u0026gt; (functor) =\u0026gt; (target) =\u0026gt; functor(getter(target)).map((focus) =\u0026gt; setter(focus, target)) ); I know how you feel about this cryptic function. Just ignore it, for now. We’ll come back to it when we’re ready.\nLet’s simplify the makeLens function a bit and make the getter and setter ready:\nconst lensProp = (k) =\u0026gt; makeLens(prop(k), assoc(k)); Here come the mighty functors:\nconst getFunctor = (x) =\u0026gt; Object.freeze({ value: x, map: (f) =\u0026gt; getFunctor(x), }); const setFunctor = (x) =\u0026gt; Object.freeze({ value: x, map: (f) =\u0026gt; setFunctor(f(x)), }); You can see they are very similar as the Box functor we’ve defined earlier. We use Object.freeze() to prevent mutations, as mutations in functional programming are forbidden.The getFunctor just ignores the mapping function and always returns the initial value, seems like very silly.\nNow, we’re finally ready to make something useful!\nconst view = curry((lens, obj) =\u0026gt; lens(getFunctor)(obj).value); const sample = { foo: { bar: { ha: 6 } } }; const lensFoo = lensProp(\u0026#34;foo\u0026#34;); view(lensFoo, sample); // =\u0026gt; {bar: {ha: 6}} Yay! After so much cryptic code, we are finally able to get a value out from an object! 🤣\nBefore we continue, let’s reason about the above code.\nWhen we call lens with getFunctor, and later call getFunctor with a value pulled out by the getter function provided earlier, we get a very simple computational context. In the case of getFunctor, this context just provides the initial value and ignores mapping operations later.\nLet’s look at set operations:\nconst over = curry((lens, f, obj) =\u0026gt; lens((y) =\u0026gt; setFunctor(f(y)))(obj).value); const always = (a) =\u0026gt; (b) =\u0026gt; a; const set = curry((lens, val, obj) =\u0026gt; over(lens, always(val), sample)); set(lensFoo, 5, sample); // =\u0026gt; {foo: 5} This time, the setFunctor doesn’t ignore mapping operations, so the operation map(focus =\u0026gt; setter(focus, target)) from the makeLens function will be performed, giving us the opportunity to transform the value returned by the getter function.\nThe always function looks silly, but look at how we use it to implement set, it’s a useful one!\nThe power of lenses Based on the examples I gave earlier, it’s not obvious how useful lenses can be. In JavaScript, we can read and set values in objects very easily. It seems like there’s no need for all the hassles!\nThe power of lenses comes from their composability. Let’s first define a compose function:\nconst compose = (...fns) =\u0026gt; (args) =\u0026gt; fns.reduceRight((x, f) =\u0026gt; f(x), args); Then we can read the inner values of the sample object like this:\nconst lensFoo = lensProp(\u0026#34;foo\u0026#34;); const lensBar = lensProp(\u0026#34;bar\u0026#34;); const lensFooBar = compose(lensFoo, lensBar); view(lensFooBar, sample); // =\u0026gt; {ha: 6} We can write a helper function to help us to get the inner lens:\nconst lensPath = (path) =\u0026gt; compose(...path.map(lensProp)); const lensHa = lensPath([\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;ha\u0026#34;]); const add = (a) =\u0026gt; (b) =\u0026gt; a + b; view(lensHa, sample); // =\u0026gt; 6 over(lensHa, add(2), sample); // =\u0026gt; {foo: {bar: {ha: 8}}} Ok, I know you must be thinking: how’s this powerful? I can achieve the same thing using lodash _.get()! Stay patient!\nLet’s consider another example. Say we have an app that lets users log their body weight. Users can fill in with both killograms and pounds. To avoid data redundancy, we only stores user records in killograms. Here\u0026rsquo;s a user record:\nconst user = { weightInKg: 65 }; We know that we have the following conversion rate between kg and lb:\nconst kgToLb = (kg) =\u0026gt; 2.20462262 * kg; const lbToKg = (lb) =\u0026gt; 0.45359237 * lb; If we want to display the user\u0026rsquo;s weight in pounds, we can get the weight in kg, and convert it to lb, which is a very straightforward approach. But we can do it more smoothly with lenses:\nconst weightInKg = lensProp(\u0026#34;weightInKg\u0026#34;); const lensLb = lens(kgToLb, lbToKg); const inLb = compose(lensLb, weightInKg); view(inLb, user); // -\u0026gt; 143.3 This looks neat. We provide different lenses to the view function, it will return us a tailored result, and the target data remains untouched.\nSuppose that the user one day adds 5 pounds to his record, the data can be updated easily like this:\nover(inLb, add(5), user); // -\u0026gt; 67.27 Wow! That reads like plain English. Without digging into the implementation details, we can interpret the operation as this: under this lens, I want to add 5 to the user record. I don\u0026rsquo;t care in what unit the stored data may be, just do it for me! The power of declarative programming really shines in this example.\n","permalink":"https://leihuang.me/posts/lens-in-js/","summary":"\u003cp\u003eWhen I was reading \n\n\u003ca href=\"https://medium.com/javascript-scene/lenses-b85976cb0534\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\n  Eric Elliott's article on Lenses\n  \u003csvg\n    xmlns=\"http://www.w3.org/2000/svg\"\n    width=\"16\"\n    height=\"16\"\n    viewBox=\"0 0 24 24\"\n    fill=\"none\"\n    stroke=\"currentColor\"\n    stroke-width=\"2\"\n    stroke-linecap=\"round\"\n    stroke-linejoin=\"round\"\n    class=\"external-icon\"\n  \u003e\n    \u003cpath d=\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"\u003e\u003c/path\u003e\n    \u003cpolyline points=\"15 3 21 3 21 9\"\u003e\u003c/polyline\u003e\n    \u003cline x1=\"10\" y1=\"14\" x2=\"21\" y2=\"3\"\u003e\u003c/line\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e,\nI was curious about how such beautiful magic can be fully implemented in\nJavaScript. It was a tough exploration. Many of the tutorials online are about\nHaskell, which cannot be easily translated to JavaScript. I read the source code\nof Ramda and finally grokked how it works.\u003c/p\u003e","title":"Introduction to Lenses in JavaScript"},{"content":"I came across this article (written in Chinese) the other day. It was about parabolic curve animation in vanilla JS. I wondered how RxJS can implement this. Below is the result of my investigation.\nImagine we take a perspective from a slow-motion camera. What humans see as a smooth animation is just an object that is put at different places at every fragment of a time period. This can be expressed as a \u0026lsquo;stream\u0026rsquo; of object position. The mechanism of an animation can be simplified by somehow mapping every fragment of a time period to a position point in space. In practice, time cannot be fragmented indefinitely, what we want is an approximation of an \u0026ldquo;atomic time unit\u0026rdquo;. The browser has provided us a tool to achieve this, which is the requestAnimationFrame API.\nWe can map every timestamp emitted by requestAnimationFrame to a position coordinate at the screen. Let\u0026rsquo;s see how we can do this in Rxjs!\nGenerating time sequence // I only demonstrate the import part once, // they will be omitted in later code. import { interval, animationFrameScheduler, fromEvent, defer, merge, } from \u0026#34;rxjs\u0026#34;; import { map, takeWhile, tap, flatMap } from \u0026#34;rxjs/operators\u0026#34;; function duration(ms) { return defer(() =\u0026gt; { const start = Date.now(); return interval(0, animationFrameScheduler).pipe( map(() =\u0026gt; (Date.now() - start) / ms), takeWhile((n) =\u0026gt; n \u0026lt;= 1) ); }); } What defer does is to only create a new observable upon being subscribed. This is to ensure every subscriber gets a new observable, otherwise, we\u0026rsquo;ll see weird movements.\nFirst, we record the animation beginning time, then we return an interval function that will emit an event every 0 seconds. This seems ridiculous. However, notice the animationFrameScheduler, it schedules at which point the interval function can emit an event. This is how we simulate an atomic time unit. The map function maps every time unit emitted by interval to a time ratio of current elapse to the whole animation duration. takeWhile ensures we unsubscribe to interval once we reach the end. We know we\u0026rsquo;ve reached the end if the current elapse equals the total time.\nThen we calculate how far the object is away from the origin at every point in time.\nMove the object const distance = (d) =\u0026gt; (t) =\u0026gt; d * t; d is the total distance the object is going to move. t is the time ratio, which has been calculated in the last step. We multiply them and get the distance at that point.\nWe get the target in the DOM and move it.\nconst targetDiv = document.querySelector(\u0026#34;.target\u0026#34;); const moveRight$ = duration(1500).pipe( map(distance(1000)), tap((x) =\u0026gt; (targetDiv.style.left = x + \u0026#34;px\u0026#34;)) ); const moveDown$ = duration(900).pipe( map(distance(700)), tap((y) =\u0026gt; (targetDiv.style.top = y + \u0026#34;px\u0026#34;)) ); The first stream moves the object to the right, the second to the bottom. Notice that the animation hasn\u0026rsquo;t taken place, because we haven\u0026rsquo;t\u0026rsquo; subscribed to them yet.\nWe combine these two streams into a new stream, making the object move rightwards and downwards at the same time.\nmerge(moveRight$, moveDown$).subscribe(); This is boring, we don\u0026rsquo;t see any curve yet. But bear with me.\nMake the motion trajectory parabolic! I hope you still remember middle school math. If you don\u0026rsquo;t, fret not. It\u0026rsquo;s pretty intuitive actually. What we observe as a curve movement is the result of an object moves at different speeds in different directions. The shape of the curve can be expressed in a mathematical equation. Take a look of the graph of the equation y = x^3, the left and right half of it is the parabolic curve we want: If we can make the downward speed and rightward speed form a cubic equation, then we have a parabolic curve movement!\nWe can use two different easing functions that form a cubic relationship between them:\nThe first one is easeInQuad：\nconst easeInQuad = (t) =\u0026gt; t * t; The second one is easeInQuint：\nconst easeInQuint = (t) =\u0026gt; Math.pow(t, 6); Then we only need to map the time ratio emitted from the interval pipeline to the result of applying these easing functions:\nconst moveDown$ = duration(900).pipe( map(easeInQuint), map(distance(700)), tap((y) =\u0026gt; (targetDiv.style.top = y + \u0026#34;px\u0026#34;)) ); const moveRight$ = duration(1500).pipe( map(easeInQuad), map(distance(1000)), tap((x) =\u0026gt; (targetDiv.style.left = x + \u0026#34;px\u0026#34;)) ); See the codepen below for the result and the complete code:\nSee the Pen{' '} Rx .js parabola animation{' '} by Lei (@leihuang) on{' '} CodePen. ","permalink":"https://leihuang.me/posts/curve-animation-in-js/","summary":"\u003cp\u003eI came across \n\n\u003ca href=\"https://juejin.im/post/5bb0b7fae51d450e62380ef3\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\n   this article (written in Chinese)\n  \u003csvg\n    xmlns=\"http://www.w3.org/2000/svg\"\n    width=\"16\"\n    height=\"16\"\n    viewBox=\"0 0 24 24\"\n    fill=\"none\"\n    stroke=\"currentColor\"\n    stroke-width=\"2\"\n    stroke-linecap=\"round\"\n    stroke-linejoin=\"round\"\n    class=\"external-icon\"\n  \u003e\n    \u003cpath d=\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"\u003e\u003c/path\u003e\n    \u003cpolyline points=\"15 3 21 3 21 9\"\u003e\u003c/polyline\u003e\n    \u003cline x1=\"10\" y1=\"14\" x2=\"21\" y2=\"3\"\u003e\u003c/line\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e the other day. It was about parabolic curve animation in vanilla JS. I\nwondered how RxJS can implement this. Below is the result of my\ninvestigation.\u003c/p\u003e\n\u003cp\u003eImagine we take a perspective from a slow-motion camera. What humans see as a\nsmooth animation is just an object that is put at different places at every\nfragment of a time period. This can be expressed as a \u0026lsquo;stream\u0026rsquo; of object\nposition. The mechanism of an animation can be simplified by somehow mapping\nevery fragment of a time period to a position point in space. In practice, time\ncannot be fragmented indefinitely, what we want is an approximation of an\n\u0026ldquo;atomic time unit\u0026rdquo;. The browser has provided us a tool to achieve this, which is\nthe \u003ccode\u003erequestAnimationFrame\u003c/code\u003e API.\u003c/p\u003e","title":"Parabolic Curve Animation With RxJS"}]